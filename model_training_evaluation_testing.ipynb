{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目前不需要但是testing data 可以參考作法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling features...\n",
      "Scaling features...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "X_val=pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test.csv')# 讀取X_test.csv\n",
    "X_train=pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')# 讀取X_train.csv\n",
    "Y_train=pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')# 讀取Y_train.csv\n",
    "# If y_train is loaded as DataFrame, convert to Series\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# Scale features(特徵縮放)\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) \n",
    "\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_val_scaled = scaler.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目前不需要，先留著"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "驗證資料筆數: 109521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成預測結果:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "處理 SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成預測結果:  33%|███▎      | 1/3 [04:58<09:56, 298.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已儲存 SVM 預測結果，筆數: 109521\n",
      "\n",
      "處理 Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成預測結果:  67%|██████▋   | 2/3 [05:01<02:04, 124.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已儲存 Logistic Regression 預測結果，筆數: 109521\n",
      "\n",
      "處理 KNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成預測結果: 100%|██████████| 3/3 [05:36<00:00, 112.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已儲存 KNN 預測結果，筆數: 109521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 1. 取得y_test的資料筆數\n",
    "y_val = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test.csv')\n",
    "val_size = len(y_val)\n",
    "print(f\"驗證資料筆數: {val_size}\")\n",
    "\n",
    "# 2. 使用Windows路徑\n",
    "save_dir = r'C:\\Users\\User\\.vscode\\thesis_experiment\\CIC-DDoS-2019\\01-12'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 3. 定義所有模型\n",
    "models = {\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# 4. 訓練模型並生成預測結果\n",
    "for name, model in tqdm(models.items(), desc=\"生成預測結果\"):\n",
    "    print(f\"\\n處理 {name}...\")\n",
    "    \n",
    "    # 訓練模型\n",
    "    model.fit(X_train_scaled, y_train) \n",
    "    \n",
    "    # 生成預測結果\n",
    "    y_pred = model.predict(X_val_scaled) #透過把訓練資料丟進去給模型，模型會生成出一個對應的預測結果(長度會跟y_val 一樣，以便比較模型是否過擬合) \n",
    "    \n",
    "    # 儲存預測結果\n",
    "    save_path = os.path.join(save_dir, f'{name.replace(\" \", \"_\")}_y_pred_val.csv')\n",
    "    pd.DataFrame(y_pred, columns=['prediction']).to_csv(save_path, index=False)\n",
    "    print(f\"已儲存 {name} 預測結果，筆數: {len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"用validation data, training data 來個別驗證經過自適應往格搜尋調整過後的SVM 模型的訓練及驗證準確(檢查模型是否會過擬合)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Scaling features...\n",
      "\n",
      "開始SVM超參數自適應優化...\n",
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數搜索範圍: {'C': [80, 90, 100, 110, 120], 'gamma': [0.008, 0.009, 0.01, 0.011, 0.012], 'kernel': ['rbf']}\n",
      "迭代 1 最佳參數: {'C': 100, 'gamma': 0.009, 'kernel': 'rbf'}\n",
      "迭代 1 最佳分數: 0.999666\n",
      "\n",
      "迭代 2/3\n",
      "當前參數搜索範圍: {'C': [80, 93, 106, 119], 'gamma': [0.008, 0.009, 0.01, 0.011], 'kernel': ['rbf']}\n",
      "迭代 2 最佳參數: {'C': 106, 'gamma': 0.009, 'kernel': 'rbf'}\n",
      "迭代 2 最佳分數: 0.999666\n",
      "\n",
      "迭代 3/3\n",
      "當前參數搜索範圍: {'C': [96, 102, 108, 114], 'gamma': [0.00825, 0.00875, 0.00925, 0.00975], 'kernel': ['rbf']}\n",
      "迭代 3 最佳參數: {'C': 102, 'gamma': 0.00875, 'kernel': 'rbf'}\n",
      "迭代 3 最佳分數: 0.999666\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "總耗時: 4009.08 秒\n",
      "最終最佳參數: {'C': 100, 'gamma': 0.009, 'kernel': 'rbf'}\n",
      "最終最佳分數: 0.999666\n",
      "\n",
      "參數優化歷史:\n",
      "迭代 1: 分數=0.999666, 參數={'C': 100, 'gamma': 0.009, 'kernel': 'rbf'}\n",
      "迭代 2: 分數=0.999666, 參數={'C': 106, 'gamma': 0.009, 'kernel': 'rbf'}\n",
      "迭代 3: 分數=0.999666, 參數={'C': 102, 'gamma': 0.00875, 'kernel': 'rbf'}\n",
      "最終最佳SVM參數: {'C': 100, 'gamma': 0.009, 'kernel': 'rbf'}\n",
      "SVM training accuracy: 0.999726\n",
      "\n",
      "Training Other Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression training complete!\n",
      "Logistic Regression validation Accuracy: 0.989542\n",
      "Training KNN...\n",
      "KNN training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:56<00:00, 58.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN validation Accuracy: 0.999767\n",
      "\n",
      "Evaluating Models on validation Set...\n",
      "\n",
      "============ The comparison of model evaluation  ============\n",
      "\n",
      "============ SVM (Adaptive) model evaluation result ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (Adaptive) (Accuracy): 0.999690\n",
      "SVM (Adaptive)  (Classification Report):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18807\n",
      "           1       1.00      1.00      1.00     90714\n",
      "\n",
      "    accuracy                           1.00    109521\n",
      "   macro avg       1.00      1.00      1.00    109521\n",
      "weighted avg       1.00      1.00      1.00    109521\n",
      "\n",
      "SVM (Adaptive)  (Confusion Matrix):\n",
      "[[18792    15]\n",
      " [   19 90695]]\n",
      "===========================================\n",
      "\n",
      "============ Logistic Regression model evaluation result ============\n",
      "Logistic Regression (Accuracy): 0.985793\n",
      "Logistic Regression  (Classification Report):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     18807\n",
      "           1       1.00      0.98      0.99     90714\n",
      "\n",
      "    accuracy                           0.99    109521\n",
      "   macro avg       0.96      0.99      0.98    109521\n",
      "weighted avg       0.99      0.99      0.99    109521\n",
      "\n",
      "Logistic Regression  (Confusion Matrix):\n",
      "[[18714    93]\n",
      " [ 1463 89251]]\n",
      "===========================================\n",
      "\n",
      "============ KNN model evaluation result ============\n",
      "KNN (Accuracy): 0.999407\n",
      "KNN  (Classification Report):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18807\n",
      "           1       1.00      1.00      1.00     90714\n",
      "\n",
      "    accuracy                           1.00    109521\n",
      "   macro avg       1.00      1.00      1.00    109521\n",
      "weighted avg       1.00      1.00      1.00    109521\n",
      "\n",
      "KNN  (Confusion Matrix):\n",
      "[[18795    12]\n",
      " [   53 90661]]\n",
      "===========================================\n",
      "\n",
      "============ 模型性能比較 ============\n",
      "SVM (Adaptive) 模型驗證準確率: 0.999690\n",
      "Logistic Regression 模型驗證準確率: 0.985793\n",
      "KNN 模型驗證準確率: 0.999407\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 添加自適應參數範圍優化類\n",
    "class AdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, cv=5, scoring='accuracy', n_iterations=3):\n",
    "        \"\"\"\n",
    "        自適應參數範圍優化器\n",
    "        \n",
    "        參數:\n",
    "        estimator: 模型估計器\n",
    "        param_grid: 初始參數網格\n",
    "        cv: 交叉驗證折數\n",
    "        scoring: 評分標準\n",
    "        n_iterations: 迭代優化次數\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.best_estimator_ = None\n",
    "        self.optimization_history = []\n",
    "        \n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        \"\"\"根據當前最佳參數生成新的搜索範圍\"\"\"\n",
    "        new_param_grid = {}\n",
    "        shrink_factor = 0.5 / (iteration + 1)  # 範圍收縮因子，隨迭代次數增加而減小\n",
    "        \n",
    "        for param_name, param_value in best_params.items():\n",
    "            if param_name not in param_grid or isinstance(param_grid[param_name][0], str):\n",
    "                # 對於分類參數(如kernel)，直接使用最佳值\n",
    "                new_param_grid[param_name] = [param_value]\n",
    "                continue\n",
    "                \n",
    "            current_values = param_grid[param_name]\n",
    "            \n",
    "            if len(current_values) <= 1:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "                \n",
    "            # 找出當前最佳值在參數列表中的位置\n",
    "            try:\n",
    "                idx = current_values.index(param_value)\n",
    "            except ValueError:\n",
    "                # 如果最佳值不在列表中，找最接近的值\n",
    "                idx = min(range(len(current_values)), \n",
    "                         key=lambda i: abs(current_values[i] - param_value))\n",
    "            \n",
    "            # 計算新的參數範圍\n",
    "            param_range = max(current_values) - min(current_values)\n",
    "            delta = param_range * shrink_factor\n",
    "            \n",
    "            if param_range < 1e-10:  # 如果範圍已經非常小，則不再縮小\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "                \n",
    "            # 根據參數類型決定如何生成新值\n",
    "            if isinstance(param_value, int):\n",
    "                # 整數參數\n",
    "                lower = max(int(param_value - delta), min(current_values))\n",
    "                upper = min(int(param_value + delta), max(current_values))\n",
    "                \n",
    "                # 確保至少有3個值\n",
    "                if lower == upper:\n",
    "                    new_values = [lower]\n",
    "                else:\n",
    "                    step = max(1, (upper - lower) // 3)\n",
    "                    new_values = list(range(lower, upper + 1, step))\n",
    "            else:\n",
    "                # 浮點數參數\n",
    "                lower = max(param_value - delta, min(current_values))\n",
    "                upper = min(param_value + delta, max(current_values))\n",
    "                \n",
    "                # 生成更精細的網格\n",
    "                step = (upper - lower) / 3\n",
    "                new_values = [round(lower + i * step, 6) for i in range(4)]  # 包括上界\n",
    "            \n",
    "            # 確保參數值的獨特性和排序\n",
    "            new_param_grid[param_name] = sorted(list(set(new_values)))\n",
    "            \n",
    "        return new_param_grid\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"執行自適應網格搜索\"\"\"\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "        \n",
    "        print(\"開始自適應參數範圍優化...\")\n",
    "        \n",
    "        for i in range(self.n_iterations):\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "            \n",
    "            # 執行當前迭代的GridSearchCV\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_param_grid, \n",
    "                cv=self.cv, \n",
    "                scoring=self.scoring,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "            # 更新最佳參數和分數\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            \n",
    "            # 記錄這次迭代的結果\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score\n",
    "            })\n",
    "            \n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "            \n",
    "            # 更新全局最佳結果\n",
    "            if i == 0 or iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = grid_search.best_estimator_\n",
    "            \n",
    "            # 為下一次迭代生成新的參數網格\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    iteration_best_params, \n",
    "                    current_param_grid,\n",
    "                    i\n",
    "                )\n",
    "        \n",
    "        # 打印優化總結\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"總耗時: {elapsed_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        \n",
    "        # 展示優化過程\n",
    "        print(\"\\n參數優化歷史:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"迭代 {history['iteration']}: 分數={history['best_score']:.6f}, 參數={history['best_params']}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# 1. 資料載入\n",
    "print(\"Loading data...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_val = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test.csv')\n",
    "y_val = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test.csv')\n",
    "\n",
    "# 將 Y_train 轉換為 Series\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 2. 特徵縮放\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. 自適應參數範圍優化 (針對 SVM)\n",
    "print(\"\\n開始SVM超參數自適應優化...\")\n",
    "# 初始參數網格定義\n",
    "param_grid = {\n",
    "    'C': [80, 90, 100, 110, 120],              # 擴大初始範圍以便更好地探索\n",
    "    'gamma': [0.008, 0.009, 0.01, 0.011, 0.012], # 擴大初始範圍\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# 使用自適應網格搜索替代傳統GridSearchCV\n",
    "svm_model = SVC(random_state=42)\n",
    "adaptive_search = AdaptiveGridSearch(\n",
    "    svm_model, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_iterations=3  # 執行3次迭代優化\n",
    ")\n",
    "\n",
    "# 執行自適應搜索\n",
    "adaptive_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 獲取最佳參數和最佳模型\n",
    "best_svm_model = adaptive_search.best_estimator_\n",
    "best_params = adaptive_search.best_params_\n",
    "print(f'最終最佳SVM參數: {best_params}')\n",
    "\n",
    "# 計算最佳 SVM 模型的訓練準確率\n",
    "train_accuracy_svm = best_svm_model.score(X_train_scaled, y_train)\n",
    "print(f'SVM training accuracy: {train_accuracy_svm:.6f}')\n",
    "\n",
    "# 4. 其他模型訓練與評估 (Logistic Regression, KNN)\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "print(\"\\nTraining Other Models...\")\n",
    "for name, model in tqdm(models.items()):\n",
    "    print(f'Training {name}...')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print(f'{name} training complete!')\n",
    "    train_accuracy = model.score(X_train_scaled, y_train)\n",
    "    print(f'{name} validation Accuracy: {train_accuracy:.6f}')\n",
    "\n",
    "# 5. 測試集評估 (所有模型)\n",
    "print(\"\\nEvaluating Models on validation Set...\")\n",
    "\n",
    "# 6. 定義評估指標\n",
    "def evaluate_model(model, X_val, y_val, model_name=\"Model\"):\n",
    "    \"\"\"評估模型性能，並輸出結果。\"\"\"\n",
    "    # 預測測試集\n",
    "    y_pred_val = model.predict(X_val_scaled) #透過把validation data丟進去給經過自適應往格搜尋的模型，模型會生成一個對應的預測結果(長度會跟y_val 一樣，以便比較模型是否過擬合)\n",
    "\n",
    "    # 計算準確率\n",
    "    accuracy = accuracy_score(y_val, y_pred_val)\n",
    "    print(f\"{model_name} (Accuracy): {accuracy:.6f}\")\n",
    "\n",
    "    # 產生分類報告\n",
    "    report = classification_report(y_val, y_pred_val)\n",
    "    print(f\"{model_name}  (Classification Report):\\n{report}\")\n",
    "\n",
    "    # 計算混淆矩陣\n",
    "    cm = confusion_matrix(y_val, y_pred_val)\n",
    "    print(f\"{model_name}  (Confusion Matrix):\\n{cm}\")\n",
    "    \n",
    "    # 返回關鍵指標用於比較\n",
    "    return {\n",
    "        'validation accuracy': accuracy,\n",
    "        'validation report': report,\n",
    "        'validation confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# 7. 評估每個模型\n",
    "all_models = {\n",
    "    'SVM (Adaptive)': best_svm_model,\n",
    "    'Logistic Regression': models['Logistic Regression'],\n",
    "    'KNN': models['KNN']\n",
    "}\n",
    "\n",
    "print(\"\\n============ The comparison of model evaluation  ============\")\n",
    "results = {}\n",
    "for name, model in all_models.items():\n",
    "    print(f\"\\n============ {name} model evaluation result ============\")\n",
    "    results[name] = evaluate_model(model, X_val_scaled, y_val, model_name=name)\n",
    "    print(\"===========================================\")\n",
    "\n",
    "# 8. 比較模型性能\n",
    "print(\"\\n============ 模型性能比較 ============\")\n",
    "for name, result in results.items():\n",
    "    print(f\"{name} 模型驗證準確率: {result['validation accuracy']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"用validation data, training data  來個別驗證經過自適應往格搜尋調整過後的KNN模型的訓練及驗證準確(檢查模型是否會過擬合)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Scaling features...\n",
      "\n",
      "開始KNN超參數自適應優化...\n",
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數搜索範圍: {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]}\n",
      "迭代 1 最佳參數: {'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 1 最佳分數: 0.999799\n",
      "\n",
      "迭代 2/3\n",
      "當前參數搜索範圍: {'algorithm': ['auto'], 'n_neighbors': [3, 4, 5, 6, 7], 'p': [1], 'weights': ['distance']}\n",
      "迭代 2 最佳參數: {'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 2 最佳分數: 0.999799\n",
      "\n",
      "迭代 3/3\n",
      "當前參數搜索範圍: {'algorithm': ['auto'], 'n_neighbors': [3, 4], 'p': [1], 'weights': ['distance']}\n",
      "迭代 3 最佳參數: {'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 3 最佳分數: 0.999799\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "總耗時: 24248.85 秒\n",
      "最終最佳參數: {'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "最終最佳分數: 0.999799\n",
      "\n",
      "參數優化歷史:\n",
      "迭代 1: 分數=0.999799, 參數={'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 2: 分數=0.999799, 參數={'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 3: 分數=0.999799, 參數={'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "最終最佳KNN參數: {'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "KNN training accuracy: 1.000000\n",
      "\n",
      "============ KNN (Adaptive) model evaluation result ============\n",
      "KNN (Adaptive) Validation Accuracy: 0.999680\n",
      "KNN (Adaptive) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18807\n",
      "           1       1.00      1.00      1.00     90714\n",
      "\n",
      "    accuracy                           1.00    109521\n",
      "   macro avg       1.00      1.00      1.00    109521\n",
      "weighted avg       1.00      1.00      1.00    109521\n",
      "\n",
      "KNN (Adaptive) Confusion Matrix:\n",
      "[[18799     8]\n",
      " [   27 90687]]\n",
      "===========================================\n",
      "\n",
      "============ KNN最佳參數總結 ============\n",
      "KNN最佳參數: {'algorithm': 'auto', 'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "KNN最佳驗證準確率: 0.999680\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 添加自適應參數範圍優化類\n",
    "class AdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, cv=5, scoring='accuracy', n_iterations=3):\n",
    "        \"\"\"\n",
    "        自適應參數範圍優化器\n",
    "        \n",
    "        參數:\n",
    "        estimator: 模型估計器\n",
    "        param_grid: 初始參數網格\n",
    "        cv: 交叉驗證折數\n",
    "        scoring: 評分標準\n",
    "        n_iterations: 迭代優化次數\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.best_estimator_ = None\n",
    "        self.optimization_history = []\n",
    "        \n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        \"\"\"根據當前最佳參數生成新的搜索範圍\"\"\"\n",
    "        new_param_grid = {}\n",
    "        shrink_factor = 0.5 / (iteration + 1)  # 範圍收縮因子，隨迭代次數增加而減小\n",
    "        \n",
    "        for param_name, param_value in best_params.items():\n",
    "            if param_name not in param_grid or isinstance(param_grid[param_name][0], str):\n",
    "                # 對於分類參數(如algorithm)，直接使用最佳值\n",
    "                new_param_grid[param_name] = [param_value]\n",
    "                continue\n",
    "                \n",
    "            current_values = param_grid[param_name]\n",
    "            \n",
    "            if len(current_values) <= 1:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "                \n",
    "            # 找出當前最佳值在參數列表中的位置\n",
    "            try:\n",
    "                idx = current_values.index(param_value)\n",
    "            except ValueError:\n",
    "                # 如果最佳值不在列表中，找最接近的值\n",
    "                idx = min(range(len(current_values)), \n",
    "                         key=lambda i: abs(current_values[i] - param_value))\n",
    "            \n",
    "            # 計算新的參數範圍\n",
    "            param_range = max(current_values) - min(current_values)\n",
    "            delta = param_range * shrink_factor\n",
    "            \n",
    "            if param_range < 1e-10:  # 如果範圍已經非常小，則不再縮小\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "                \n",
    "            # 根據參數類型決定如何生成新值\n",
    "            if isinstance(param_value, int):\n",
    "                # 整數參數\n",
    "                lower = max(int(param_value - delta), min(current_values))\n",
    "                upper = min(int(param_value + delta), max(current_values))\n",
    "                \n",
    "                # 確保至少有3個值\n",
    "                if lower == upper:\n",
    "                    new_values = [lower]\n",
    "                else:\n",
    "                    step = max(1, (upper - lower) // 3)\n",
    "                    new_values = list(range(lower, upper + 1, step))\n",
    "            else:\n",
    "                # 浮點數參數\n",
    "                lower = max(param_value - delta, min(current_values))\n",
    "                upper = min(param_value + delta, max(current_values))\n",
    "                \n",
    "                # 生成更精細的網格\n",
    "                step = (upper - lower) / 3\n",
    "                new_values = [round(lower + i * step, 6) for i in range(4)]  # 包括上界\n",
    "            \n",
    "            # 確保參數值的獨特性和排序\n",
    "            new_param_grid[param_name] = sorted(list(set(new_values)))\n",
    "            \n",
    "        return new_param_grid\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"執行自適應網格搜索\"\"\"\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "        \n",
    "        print(\"開始自適應參數範圍優化...\")\n",
    "        \n",
    "        for i in range(self.n_iterations):\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "            \n",
    "            # 執行當前迭代的GridSearchCV\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_param_grid, \n",
    "                cv=self.cv, \n",
    "                scoring=self.scoring,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "            # 更新最佳參數和分數\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            \n",
    "            # 記錄這次迭代的結果\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score\n",
    "            })\n",
    "            \n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "            \n",
    "            # 更新全局最佳結果\n",
    "            if i == 0 or iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = grid_search.best_estimator_\n",
    "            \n",
    "            # 為下一次迭代生成新的參數網格\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    iteration_best_params, \n",
    "                    current_param_grid,\n",
    "                    i\n",
    "                )\n",
    "        \n",
    "        # 打印優化總結\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"總耗時: {elapsed_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        \n",
    "        # 展示優化過程\n",
    "        print(\"\\n參數優化歷史:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"迭代 {history['iteration']}: 分數={history['best_score']:.6f}, 參數={history['best_params']}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# 1. 資料載入\n",
    "print(\"Loading data...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_val = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test.csv')\n",
    "y_val = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test.csv')\n",
    "\n",
    "\n",
    "# 將 Y_train 轉換為 Series\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 2. 特徵縮放\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. 對KNN進行自適應參數範圍優化\n",
    "print(\"\\n開始KNN超參數自適應優化...\")\n",
    "# 初始參數網格定義\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2]  # p=1 為曼哈頓距離，p=2 為歐氏距離\n",
    "}\n",
    "\n",
    "# 使用自適應網格搜索\n",
    "knn_model = KNeighborsClassifier()\n",
    "adaptive_search_knn = AdaptiveGridSearch(\n",
    "    knn_model,\n",
    "    knn_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_iterations=3\n",
    ")\n",
    "\n",
    "# 執行自適應搜索\n",
    "adaptive_search_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 獲取最佳參數和最佳模型\n",
    "best_knn_model = adaptive_search_knn.best_estimator_\n",
    "best_knn_params = adaptive_search_knn.best_params_\n",
    "print(f'最終最佳KNN參數: {best_knn_params}')\n",
    "\n",
    "# 計算最佳 KNN 模型的訓練準確率\n",
    "train_accuracy_knn = best_knn_model.score(X_train_scaled, y_train)\n",
    "print(f'KNN training accuracy: {train_accuracy_knn:.6f}')\n",
    "\n",
    "# 4. 定義評估指標\n",
    "def evaluate_model(model, X_val, y_val, model_name=\"Model\"):\n",
    "    \"\"\"評估模型性能，並輸出結果。\"\"\"\n",
    "    # 預測測試集\n",
    "    y_pred_val = model.predict(X_val_scaled)\n",
    "\n",
    "    # 計算準確率\n",
    "    accuracy = accuracy_score(y_val, y_pred_val)\n",
    "    print(f\"{model_name} Validation Accuracy: {accuracy:.6f}\")\n",
    "\n",
    "    # 產生分類報告\n",
    "    report = classification_report(y_val, y_pred_val)\n",
    "    print(f\"{model_name} Classification Report:\\n{report}\")\n",
    "\n",
    "    # 計算混淆矩陣\n",
    "    cm = confusion_matrix(y_val, y_pred_val)\n",
    "    print(f\"{model_name} Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    # 返回關鍵指標用於比較\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'report': report,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# 5. 評估最佳KNN模型\n",
    "print(\"\\n============ KNN (Adaptive) model evaluation result ============\")\n",
    "knn_results = evaluate_model(best_knn_model, X_val_scaled, y_val, model_name=\"KNN (Adaptive)\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# 6. 打印KNN的最佳參數\n",
    "print(\"\\n============ KNN最佳參數總結 ============\")\n",
    "print(f\"KNN最佳參數: {best_knn_params}\")\n",
    "print(f\"KNN最佳驗證準確率: {knn_results['accuracy']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"用validation data, training data  來個別驗證經過自適應往格搜尋調整過後的LR模型的訓練及驗證準確(檢查模型是否會過擬合)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Scaling features...\n",
      "\n",
      "開始LR超參數自適應優化...\n",
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數搜索範圍: {'C': [0.01, 0.1, 1.0, 10.0, 100.0], 'solver': ['liblinear', 'saga'], 'max_iter': [200, 500], 'tol': [0.0001]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代 1 最佳參數: {'C': 0.01, 'max_iter': 500, 'solver': 'saga', 'tol': 0.0001}\n",
      "迭代 1 最佳分數: 0.990592\n",
      "\n",
      "迭代 2/3\n",
      "當前參數搜索範圍: {'C': [0.01, 16.675, 33.34, 50.005], 'max_iter': [350, 400, 450, 500], 'solver': ['saga'], 'tol': [0.0001]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代 2 最佳參數: {'C': 0.01, 'max_iter': 400, 'solver': 'saga', 'tol': 0.0001}\n",
      "迭代 2 最佳分數: 0.990616\n",
      "\n",
      "迭代 3/3\n",
      "當前參數搜索範圍: {'C': [0.01, 4.17625, 8.3425, 12.50875], 'max_iter': [362, 387, 412, 437], 'solver': ['saga'], 'tol': [0.0001]}\n",
      "迭代 3 最佳參數: {'C': 0.01, 'max_iter': 437, 'solver': 'saga', 'tol': 0.0001}\n",
      "迭代 3 最佳分數: 0.990616\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "總耗時: 1731.65 秒\n",
      "最終最佳參數: {'C': 0.01, 'max_iter': 400, 'solver': 'saga', 'tol': 0.0001}\n",
      "最終最佳分數: 0.990616\n",
      "\n",
      "參數優化歷史:\n",
      "迭代 1: 分數=0.990592, 參數={'C': 0.01, 'max_iter': 500, 'solver': 'saga', 'tol': 0.0001}\n",
      "迭代 2: 分數=0.990616, 參數={'C': 0.01, 'max_iter': 400, 'solver': 'saga', 'tol': 0.0001}\n",
      "迭代 3: 分數=0.990616, 參數={'C': 0.01, 'max_iter': 437, 'solver': 'saga', 'tol': 0.0001}\n",
      "\n",
      "============ LR (Adaptive) model evaluation result ============\n",
      "LR (Adaptive) Training Accuracy: 0.990638\n",
      "LR (Adaptive) Validation Accuracy: 0.986496\n",
      "LR (Adaptive) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     18807\n",
      "           1       1.00      0.98      0.99     90714\n",
      "\n",
      "    accuracy                           0.99    109521\n",
      "   macro avg       0.96      0.99      0.98    109521\n",
      "weighted avg       0.99      0.99      0.99    109521\n",
      "\n",
      "LR (Adaptive) Confusion Matrix:\n",
      "[[18743    64]\n",
      " [ 1415 89299]]\n",
      "===========================================\n",
      "\n",
      "============ LR最佳參數總結 ============\n",
      "LR最佳參數: {'C': 0.01, 'max_iter': 400, 'solver': 'saga', 'tol': 0.0001}\n",
      "LR最佳驗證準確率: 0.986496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 自適應參數範圍優化類\n",
    "class AdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, cv=5, scoring='accuracy', n_iterations=3):\n",
    "        \"\"\"\n",
    "        自適應參數範圍優化器\n",
    "        \n",
    "        參數:\n",
    "        estimator: 模型估計器\n",
    "        param_grid: 初始參數網格\n",
    "        cv: 交叉驗證折數\n",
    "        scoring: 評分標準\n",
    "        n_iterations: 迭代優化次數\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.best_estimator_ = None\n",
    "        self.optimization_history = []\n",
    "        \n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        \"\"\"根據當前最佳參數生成新的搜索範圍\"\"\"\n",
    "        new_param_grid = {}\n",
    "        shrink_factor = 0.5 / (iteration + 1)  # 範圍收縮因子，隨迭代次數增加而減小\n",
    "        \n",
    "        for param_name, param_value in best_params.items():\n",
    "            if param_name not in param_grid or isinstance(param_grid[param_name][0], str):\n",
    "                # 對於分類參數(如solver, penalty)，直接使用最佳值\n",
    "                new_param_grid[param_name] = [param_value]\n",
    "                continue\n",
    "                \n",
    "            current_values = param_grid[param_name]\n",
    "            \n",
    "            if len(current_values) <= 1:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "                \n",
    "            # 找出當前最佳值在參數列表中的位置\n",
    "            try:\n",
    "                idx = current_values.index(param_value)\n",
    "            except ValueError:\n",
    "                # 如果最佳值不在列表中，找最接近的值\n",
    "                idx = min(range(len(current_values)), \n",
    "                         key=lambda i: abs(current_values[i] - param_value))\n",
    "            \n",
    "            # 計算新的參數範圍\n",
    "            param_range = max(current_values) - min(current_values)\n",
    "            delta = param_range * shrink_factor\n",
    "            \n",
    "            if param_range < 1e-10:  # 如果範圍已經非常小，則不再縮小\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "                \n",
    "            # 根據參數類型決定如何生成新值\n",
    "            if isinstance(param_value, int):\n",
    "                # 整數參數\n",
    "                lower = max(int(param_value - delta), min(current_values))\n",
    "                upper = min(int(param_value + delta), max(current_values))\n",
    "                \n",
    "                # 確保至少有3個值\n",
    "                if lower == upper:\n",
    "                    new_values = [lower]\n",
    "                else:\n",
    "                    step = max(1, (upper - lower) // 3)\n",
    "                    new_values = list(range(lower, upper + 1, step))\n",
    "            else:\n",
    "                # 浮點數參數\n",
    "                lower = max(param_value - delta, min(current_values))\n",
    "                upper = min(param_value + delta, max(current_values))\n",
    "                \n",
    "                # 生成更精細的網格\n",
    "                step = (upper - lower) / 3\n",
    "                new_values = [round(lower + i * step, 6) for i in range(4)]  # 包括上界\n",
    "            \n",
    "            # 確保參數值的獨特性和排序\n",
    "            new_param_grid[param_name] = sorted(list(set(new_values)))\n",
    "            \n",
    "        return new_param_grid\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"執行自適應網格搜索\"\"\"\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "        \n",
    "        print(\"開始自適應參數範圍優化...\")\n",
    "        \n",
    "        for i in range(self.n_iterations):\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "            \n",
    "            # 執行當前迭代的GridSearchCV\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_param_grid, \n",
    "                cv=self.cv, \n",
    "                scoring=self.scoring,\n",
    "                n_jobs=-1,\n",
    "                verbose=0  # 減少輸出\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "            # 更新最佳參數和分數\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            \n",
    "            # 記錄這次迭代的結果\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score\n",
    "            })\n",
    "            \n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "            \n",
    "            # 更新全局最佳結果\n",
    "            if i == 0 or iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = grid_search.best_estimator_\n",
    "            \n",
    "            # 為下一次迭代生成新的參數網格\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    iteration_best_params, \n",
    "                    current_param_grid,\n",
    "                    i\n",
    "                )\n",
    "        \n",
    "        # 打印優化總結\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"總耗時: {elapsed_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        \n",
    "        # 展示優化過程\n",
    "        print(\"\\n參數優化歷史:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"迭代 {history['iteration']}: 分數={history['best_score']:.6f}, 參數={history['best_params']}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# 1. 資料載入\n",
    "print(\"Loading data...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_val = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test.csv')\n",
    "y_val = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test.csv')\n",
    "\n",
    "# 將 Y_train 轉換為 Series\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 2. 特徵縮放\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. 對LR進行自適應參數範圍優化\n",
    "print(\"\\n開始LR超參數自適應優化...\")\n",
    "\n",
    "# 定義更新過的參數網格\n",
    "lr_param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # 更新了C的範圍\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [200, 500],\n",
    "    'tol': [1e-4]\n",
    "}\n",
    "\n",
    "# 使用自適應網格搜索\n",
    "adaptive_search_lr = AdaptiveGridSearch(\n",
    "    LogisticRegression(random_state=42),\n",
    "    lr_param_grid,\n",
    "    cv=3,  # 減少交叉驗證折數以加速\n",
    "    scoring='accuracy',\n",
    "    n_iterations=3  # 設定迭代次數\n",
    ")\n",
    "\n",
    "# 執行自適應網格搜索\n",
    "adaptive_search_lr.fit(X_train_scaled, y_train)\n",
    "best_lr_model = adaptive_search_lr.best_estimator_\n",
    "best_lr_params = adaptive_search_lr.best_params_\n",
    "best_lr_score = adaptive_search_lr.best_score_\n",
    "\n",
    "# 4. 定義評估指標\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, model_name=\"Model\"):\n",
    "    \"\"\"評估模型性能，並輸出結果。\"\"\"\n",
    "    # 預測訓練集\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    # 預測測試集\n",
    "    y_pred_val = model.predict(X_val)\n",
    "\n",
    "    # 計算訓練和驗證準確率\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "    print(f\"{model_name} Training Accuracy: {train_accuracy:.6f}\")\n",
    "    print(f\"{model_name} Validation Accuracy: {val_accuracy:.6f}\")\n",
    "\n",
    "    # 產生分類報告\n",
    "    report = classification_report(y_val, y_pred_val)\n",
    "    print(f\"{model_name} Classification Report:\\n{report}\")\n",
    "\n",
    "    # 計算混淆矩陣\n",
    "    cm = confusion_matrix(y_val, y_pred_val)\n",
    "    print(f\"{model_name} Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    # 返回關鍵指標用於比較\n",
    "    return {\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'report': report,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# 5. 評估最佳LR模型\n",
    "print(\"\\n============ LR (Adaptive) model evaluation result ============\")\n",
    "lr_results = evaluate_model(best_lr_model, X_train_scaled, y_train, X_val_scaled, y_val, model_name=\"LR (Adaptive)\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# 6. 打印LR的最佳參數\n",
    "print(\"\\n============ LR最佳參數總結 ============\")\n",
    "print(f\"LR最佳參數: {best_lr_params}\")\n",
    "print(f\"LR最佳驗證準確率: {lr_results['val_accuracy']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"用tesing data(之前模型都沒有看過的測試資料(資料夾03-11)來個別測試經經過自適應往格搜尋調整過後的SVM模型的測試準確率(模型最終的表現))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入資料...\n",
      "特徵標準化...\n",
      "執行 SVM 自適應搜尋...\n",
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "參數搜索範圍: {'C': [1, 10, 100, 500, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['rbf']}\n",
      "\n",
      "迭代 2/3\n",
      "參數搜索範圍: {'C': [500, 666, 832, 998], 'gamma': [0.0001, 0.02005, 0.04, 0.05995], 'kernel': ['rbf']}\n",
      "\n",
      "迭代 3/3\n",
      "參數搜索範圍: {'C': [873, 914, 955, 996], 'gamma': [0.044987, 0.049975, 0.054963, 0.05995], 'kernel': ['rbf']}\n",
      "\n",
      "自適應參數優化完成\n",
      "總耗時: 12899.12 秒\n",
      "最佳參數: {'C': 996, 'gamma': 0.049975, 'kernel': 'rbf'}\n",
      " 最佳交叉驗證分數: 0.999702\n",
      "\n",
      " 模型測試集評估\n",
      "測試準確率: 0.998408\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       1.00      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "\n",
      "混淆矩陣:\n",
      "[[49646   117]\n",
      " [    3 25617]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "\n",
    "# ===============================\n",
    "# 自適應參數範圍優化類別（強化版）\n",
    "# ===============================\n",
    "class AdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, cv=5, scoring='accuracy', n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.best_estimator_ = None\n",
    "        self.optimization_history = []\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        \"\"\"根據最佳參數縮小搜索範圍\"\"\"\n",
    "        new_param_grid = {}\n",
    "        shrink_factor = 0.5 / (iteration + 1)\n",
    "\n",
    "        for param, best_val in best_params.items():\n",
    "            if isinstance(param_grid[param][0], str):\n",
    "                new_param_grid[param] = [best_val]\n",
    "                continue\n",
    "\n",
    "            values = param_grid[param]\n",
    "            param_range = max(values) - min(values)\n",
    "            delta = param_range * shrink_factor\n",
    "\n",
    "            if isinstance(best_val, int):\n",
    "                lower = max(min(values), int(best_val - delta))\n",
    "                upper = min(max(values), int(best_val + delta))\n",
    "                step = max(1, (upper - lower) // 3)\n",
    "                new_values = list(range(lower, upper + 1, step))\n",
    "            else:\n",
    "                lower = max(min(values), best_val - delta)\n",
    "                upper = min(max(values), best_val + delta)\n",
    "                step = (upper - lower) / 3\n",
    "                new_values = [round(lower + i * step, 6) for i in range(4)]\n",
    "\n",
    "            new_param_grid[param] = sorted(list(set(new_values)))\n",
    "\n",
    "        return new_param_grid\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "\n",
    "        print(\"開始自適應參數範圍優化...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"參數搜索範圍: {current_param_grid}\")\n",
    "\n",
    "            grid = GridSearchCV(\n",
    "                self.estimator,\n",
    "                current_param_grid,\n",
    "                cv=self.cv,\n",
    "                scoring=self.scoring,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid.fit(X, y)\n",
    "\n",
    "            best_params = grid.best_params_\n",
    "            best_score = grid.best_score_\n",
    "\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i + 1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': best_params,\n",
    "                'best_score': best_score\n",
    "            })\n",
    "\n",
    "            if i == 0 or best_score > self.best_score_:\n",
    "                self.best_params_ = best_params\n",
    "                self.best_score_ = best_score\n",
    "                self.best_estimator_ = grid.best_estimator_\n",
    "\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    best_params, current_param_grid, i)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\n自適應參數優化完成\")\n",
    "        print(f\"總耗時: {elapsed_time:.2f} 秒\")\n",
    "        print(f\"最佳參數: {self.best_params_}\")\n",
    "        print(f\" 最佳交叉驗證分數: {self.best_score_:.6f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "print(\"載入資料...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "print(\"特徵標準化...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ===============================\n",
    "# SVM + 自適應網格搜尋\n",
    "# ===============================\n",
    "print(\"執行 SVM 自適應搜尋...\")\n",
    "initial_param_grid = {\n",
    "    'C': [1, 10, 100, 500, 1000],  # 起手範圍拉大\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "svm = SVC(random_state=42)\n",
    "adaptive_search = AdaptiveGridSearch(\n",
    "    estimator=svm,\n",
    "    param_grid=initial_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_iterations=3\n",
    ")\n",
    "\n",
    "adaptive_search.fit(X_train_scaled, y_train)\n",
    "best_svm_model = adaptive_search.best_estimator_\n",
    "\n",
    "# ===============================\n",
    "# 測試集評估\n",
    "# ===============================\n",
    "print(\"\\n 模型測試集評估\")\n",
    "y_pred = best_svm_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"測試準確率: {accuracy:.6f}\")\n",
    "print(\"\\n分類報告:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n混淆矩陣:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有調整過的自適應超參數調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Scaling features...\n",
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數搜索範圍: {'C': [1, 10, 100, 500, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['rbf']}\n",
      "迭代 1 最佳參數: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "迭代 1 最佳分數: 0.999693\n",
      "迭代 1 耗時: 4942.17 秒\n",
      "\n",
      "迭代 2/3\n",
      "當前參數搜索範圍: {'C': [500, 666, 832, 998], 'gamma': [0.0001, 0.02005, 0.04, 0.05995], 'kernel': ['rbf']}\n",
      "迭代 2 最佳參數: {'C': 998, 'gamma': 0.05995, 'kernel': 'rbf'}\n",
      "迭代 2 最佳分數: 0.999699\n",
      "迭代 2 耗時: 3372.38 秒\n",
      "\n",
      "迭代 3/3\n",
      "當前參數搜索範圍: {'C': [873, 914, 955, 996], 'gamma': [0.044987, 0.049975, 0.054963, 0.05995], 'kernel': ['rbf']}\n",
      "迭代 3 最佳參數: {'C': 996, 'gamma': 0.049975, 'kernel': 'rbf'}\n",
      "迭代 3 最佳分數: 0.999702\n",
      "迭代 3 耗時: 4441.87 秒\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "總耗時: 12756.42 秒\n",
      "最終最佳參數: {'C': 996, 'gamma': 0.049975, 'kernel': 'rbf'}\n",
      "最終最佳分數: 0.999702\n",
      "\n",
      "參數優化歷史:\n",
      "迭代 1: 分數=0.999693, 參數={'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}, 耗時=4942.17 秒\n",
      "迭代 2: 分數=0.999699, 參數={'C': 998, 'gamma': 0.05995, 'kernel': 'rbf'}, 耗時=3372.38 秒\n",
      "迭代 3: 分數=0.999702, 參數={'C': 996, 'gamma': 0.049975, 'kernel': 'rbf'}, 耗時=4441.87 秒\n",
      "\n",
      "SVM自適應網格搜尋總訓練耗時: 12756.42 秒\n",
      "\n",
      "SVM測試集準確率: 0.999571 (預測耗時: 40.45 秒)\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18807\n",
      "           1       1.00      1.00      1.00     90714\n",
      "\n",
      "    accuracy                           1.00    109521\n",
      "   macro avg       1.00      1.00      1.00    109521\n",
      "weighted avg       1.00      1.00      1.00    109521\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18800     7]\n",
      " [   40 90674]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "\n",
    "# 1. 載入資料\n",
    "print(\"Loading data...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test.csv')\n",
    "\n",
    "# Y_train 轉為 Series\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 2. 特徵縮放\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. 自適應網格搜尋類別\n",
    "class AdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, cv=5, scoring='accuracy', n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.best_estimator_ = None\n",
    "        self.optimization_history = []\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        new_param_grid = {}\n",
    "        shrink_factor = 0.5 / (iteration + 1)\n",
    "        for param_name, param_value in best_params.items():\n",
    "            if param_name not in param_grid or isinstance(param_grid[param_name][0], str):\n",
    "                new_param_grid[param_name] = [param_value]\n",
    "                continue\n",
    "            current_values = param_grid[param_name]\n",
    "            if len(current_values) <= 1:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "            try:\n",
    "                idx = current_values.index(param_value)\n",
    "            except ValueError:\n",
    "                idx = min(range(len(current_values)), key=lambda i: abs(current_values[i] - param_value))\n",
    "            param_range = max(current_values) - min(current_values)\n",
    "            delta = param_range * shrink_factor\n",
    "            if param_range < 1e-10:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "            if isinstance(param_value, int):\n",
    "                lower = max(int(param_value - delta), min(current_values))\n",
    "                upper = min(int(param_value + delta), max(current_values))\n",
    "                if lower == upper:\n",
    "                    new_values = [lower]\n",
    "                else:\n",
    "                    step = max(1, (upper - lower) // 3)\n",
    "                    new_values = list(range(lower, upper + 1, step))\n",
    "            else:\n",
    "                lower = max(param_value - delta, min(current_values))\n",
    "                upper = min(param_value + delta, max(current_values))\n",
    "                step = (upper - lower) / 3\n",
    "                new_values = [round(lower + i * step, 6) for i in range(4)]\n",
    "            new_param_grid[param_name] = sorted(list(set(new_values)))\n",
    "        return new_param_grid\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "        print(\"開始自適應參數範圍優化...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "            iter_start = time.time()\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_param_grid, \n",
    "                cv=self.cv, \n",
    "                scoring=self.scoring,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "            iter_end = time.time()\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score,\n",
    "                'iteration_time': iter_end - iter_start\n",
    "            })\n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "            print(f\"迭代 {i+1} 耗時: {iter_end - iter_start:.2f} 秒\")\n",
    "            if i == 0 or iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = grid_search.best_estimator_\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    iteration_best_params, \n",
    "                    current_param_grid,\n",
    "                    i\n",
    "                )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"總耗時: {elapsed_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        print(\"\\n參數優化歷史:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"迭代 {history['iteration']}: 分數={history['best_score']:.6f}, 參數={history['best_params']}, 耗時={history['iteration_time']:.2f} 秒\")\n",
    "        return self\n",
    "\n",
    "# 4. 定義參數範圍\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100, 500, 1000],\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# 5. 執行自適應搜尋（含總訓練耗時）\n",
    "svm_model = SVC(random_state=42)\n",
    "adaptive_search = AdaptiveGridSearch(\n",
    "    svm_model, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_iterations=3\n",
    ")\n",
    "\n",
    "total_train_start = time.time()\n",
    "adaptive_search.fit(X_train_scaled, y_train)\n",
    "total_train_end = time.time()\n",
    "print(f\"\\nSVM自適應網格搜尋總訓練耗時: {total_train_end - total_train_start:.2f} 秒\")\n",
    "\n",
    "# 6. 測試集評估（含耗時）\n",
    "test_start = time.time()\n",
    "y_pred = adaptive_search.best_estimator_.predict(X_test_scaled)\n",
    "test_end = time.time()\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nSVM測試集準確率: {test_acc:.6f} (預測耗時: {test_end - test_start:.2f} 秒)\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \"急速版的自適應(參數收縮幅度較大（shrink_factor=0.25/(iteration+1)）\"可以拿來當結果用\n",
    "\n",
    "每輪只取2~3個參數點\n",
    "\n",
    "前兩輪只用2折交叉驗證，最後一輪再用5折\n",
    "\n",
    "計算速度大幅提升，準確率仍然很高)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Scaling features...\n",
      "\n",
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數搜索範圍: {'C': [1, 10, 100, 500, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['rbf']}\n",
      "迭代 1 最佳參數: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "迭代 1 最佳分數: 0.999669\n",
      "迭代 1 耗時: 2935.02 秒\n",
      "\n",
      "迭代 2/3\n",
      "當前參數搜索範圍: {'C': [np.float64(750.25), np.float64(875.125), np.float64(1000.0)], 'gamma': [np.float64(0.0001), np.float64(0.017537), np.float64(0.034975)], 'kernel': ['rbf']}\n",
      "迭代 2 最佳參數: {'C': np.float64(875.125), 'gamma': np.float64(0.017537), 'kernel': 'rbf'}\n",
      "迭代 2 最佳分數: 0.999628\n",
      "迭代 2 耗時: 1179.61 秒\n",
      "\n",
      "迭代 3/3\n",
      "當前參數搜索範圍: {'C': [np.float64(843.90625), np.float64(875.125), np.float64(906.34375)], 'gamma': [np.float64(0.013178), np.float64(0.017537), np.float64(0.021896)], 'kernel': ['rbf']}\n",
      "迭代 3 最佳參數: {'C': np.float64(843.90625), 'gamma': np.float64(0.013178), 'kernel': 'rbf'}\n",
      "迭代 3 最佳分數: 0.999707\n",
      "迭代 3 耗時: 1432.86 秒\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "總耗時: 5547.53 秒\n",
      "最終最佳參數: {'C': np.float64(843.90625), 'gamma': np.float64(0.013178), 'kernel': 'rbf'}\n",
      "最終最佳分數: 0.999707\n",
      "\n",
      "參數優化歷史:\n",
      "迭代 1: 分數=0.999669, 參數={'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}, 耗時=2935.02 秒\n",
      "迭代 2: 分數=0.999628, 參數={'C': np.float64(875.125), 'gamma': np.float64(0.017537), 'kernel': 'rbf'}, 耗時=1179.61 秒\n",
      "迭代 3: 分數=0.999707, 參數={'C': np.float64(843.90625), 'gamma': np.float64(0.013178), 'kernel': 'rbf'}, 耗時=1432.86 秒\n",
      "\n",
      "SVM自適應網格搜尋總訓練耗時: 5547.54 秒\n",
      "\n",
      "SVM測試集準確率: 0.999753 (預測耗時: 30.29 秒)\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18807\n",
      "           1       1.00      1.00      1.00     90714\n",
      "\n",
      "    accuracy                           1.00    109521\n",
      "   macro avg       1.00      1.00      1.00    109521\n",
      "weighted avg       1.00      1.00      1.00    109521\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18796    11]\n",
      " [   16 90698]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class FastAdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        new_param_grid = {}\n",
    "        shrink_factor = 0.25 / (iteration + 1)  # 更大收縮\n",
    "        for param_name, param_value in best_params.items():\n",
    "            if param_name not in param_grid or isinstance(param_grid[param_name][0], str):\n",
    "                new_param_grid[param_name] = [param_value]\n",
    "                continue\n",
    "            current_values = param_grid[param_name]\n",
    "            param_range = max(current_values) - min(current_values)\n",
    "            delta = param_range * shrink_factor\n",
    "            if param_range < 1e-10:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "            lower = max(param_value - delta, min(current_values))\n",
    "            upper = min(param_value + delta, max(current_values))\n",
    "            # 只取3個點\n",
    "            new_values = np.linspace(lower, upper, 3)\n",
    "            new_param_grid[param_name] = sorted(list(set([round(v, 6) for v in new_values])))\n",
    "        return new_param_grid\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "        print(\"\\n開始自適應參數範圍優化...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            cv_fold = 2 if i < self.n_iterations - 1 else 5  # 前兩輪用2折，最後一輪5折\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "            iter_start = time.time()\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_param_grid, \n",
    "                cv=cv_fold, \n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "            iter_end = time.time()\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "            print(f\"迭代 {i+1} 耗時: {iter_end - iter_start:.2f} 秒\")\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score,\n",
    "                'iteration_time': iter_end - iter_start\n",
    "            })\n",
    "            if i == 0 or iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = grid_search.best_estimator_\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    iteration_best_params, \n",
    "                    current_param_grid,\n",
    "                    i\n",
    "                )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"總耗時: {elapsed_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        print(\"\\n參數優化歷史:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"迭代 {history['iteration']}: 分數={history['best_score']:.6f}, 參數={history['best_params']}, 耗時={history['iteration_time']:.2f} 秒\")\n",
    "        return self\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100, 500, 1000],\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "adaptive_search = FastAdaptiveGridSearch(\n",
    "    svm_model, \n",
    "    param_grid, \n",
    "    n_iterations=3\n",
    ")\n",
    "\n",
    "total_train_start = time.time()\n",
    "adaptive_search.fit(X_train_scaled, y_train)\n",
    "total_train_end = time.time()\n",
    "print(f\"\\nSVM自適應網格搜尋總訓練耗時: {total_train_end - total_train_start:.2f} 秒\")\n",
    "\n",
    "# 測試集評估\n",
    "test_start = time.time()\n",
    "y_pred = adaptive_search.best_estimator_.predict(X_test_scaled)\n",
    "test_end = time.time()\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nSVM測試集準確率: {test_acc:.6f} (預測耗時: {test_end - test_start:.2f} 秒)\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入資料...\n",
      "特徵標準化...\n",
      "\n",
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數搜索範圍: {'C': [1, 10, 100, 500, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['rbf']}\n",
      "迭代 1 最佳參數: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "迭代 1 最佳分數: 0.999669\n",
      "迭代 1 耗時: 2320.21 秒\n",
      "\n",
      "迭代 2/3\n",
      "當前參數搜索範圍: {'C': [np.float64(750.25), np.float64(875.125), np.float64(1000.0)], 'gamma': [np.float64(0.0001), np.float64(0.017537), np.float64(0.034975)], 'kernel': ['rbf']}\n",
      "迭代 2 最佳參數: {'C': np.float64(875.125), 'gamma': np.float64(0.017537), 'kernel': 'rbf'}\n",
      "迭代 2 最佳分數: 0.999628\n",
      "迭代 2 耗時: 590.21 秒\n",
      "\n",
      "迭代 3/3\n",
      "當前參數搜索範圍: {'C': [np.float64(843.90625), np.float64(875.125), np.float64(906.34375)], 'gamma': [np.float64(0.013178), np.float64(0.017537), np.float64(0.021896)], 'kernel': ['rbf']}\n",
      "迭代 3 最佳參數: {'C': np.float64(843.90625), 'gamma': np.float64(0.013178), 'kernel': 'rbf'}\n",
      "迭代 3 最佳分數: 0.999707\n",
      "迭代 3 耗時: 842.76 秒\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "總耗時: 3753.20 秒\n",
      "最終最佳參數: {'C': np.float64(843.90625), 'gamma': np.float64(0.013178), 'kernel': 'rbf'}\n",
      "最終最佳分數: 0.999707\n",
      "\n",
      "參數優化歷史:\n",
      "迭代 1: 分數=0.999669, 參數={'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}, 耗時=2320.21 秒\n",
      "迭代 2: 分數=0.999628, 參數={'C': np.float64(875.125), 'gamma': np.float64(0.017537), 'kernel': 'rbf'}, 耗時=590.21 秒\n",
      "迭代 3: 分數=0.999707, 參數={'C': np.float64(843.90625), 'gamma': np.float64(0.013178), 'kernel': 'rbf'}, 耗時=842.76 秒\n",
      "\n",
      "SVM自適應網格搜尋總訓練耗時: 3753.20 秒\n",
      "\n",
      "SVM測試集準確率: 0.998514 (預測耗時: 15.11 秒)\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       1.00      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "Confusion Matrix:\n",
      " [[49656   107]\n",
      " [    5 25615]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 載入資料\n",
    "print(\"載入資料...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "print(\"特徵標準化...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class FastAdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        new_param_grid = {}\n",
    "        shrink_factor = 0.25 / (iteration + 1)  # 更大收縮\n",
    "        for param_name, param_value in best_params.items():\n",
    "            if param_name not in param_grid or isinstance(param_grid[param_name][0], str):\n",
    "                new_param_grid[param_name] = [param_value]\n",
    "                continue\n",
    "            current_values = param_grid[param_name]\n",
    "            param_range = max(current_values) - min(current_values)\n",
    "            delta = param_range * shrink_factor\n",
    "            if param_range < 1e-10:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "            lower = max(param_value - delta, min(current_values))\n",
    "            upper = min(param_value + delta, max(current_values))\n",
    "            # 只取3個點\n",
    "            new_values = np.linspace(lower, upper, 3)\n",
    "            new_param_grid[param_name] = sorted(list(set([round(v, 6) for v in new_values])))\n",
    "        return new_param_grid\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "        print(\"\\n開始自適應參數範圍優化...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            cv_fold = 2 if i < self.n_iterations - 1 else 5  # 前兩輪用2折，最後一輪5折\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "            iter_start = time.time()\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_param_grid, \n",
    "                cv=cv_fold, \n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "            iter_end = time.time()\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "            print(f\"迭代 {i+1} 耗時: {iter_end - iter_start:.2f} 秒\")\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score,\n",
    "                'iteration_time': iter_end - iter_start\n",
    "            })\n",
    "            if i == 0 or iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = grid_search.best_estimator_\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    iteration_best_params, \n",
    "                    current_param_grid,\n",
    "                    i\n",
    "                )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"總耗時: {elapsed_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        print(\"\\n參數優化歷史:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"迭代 {history['iteration']}: 分數={history['best_score']:.6f}, 參數={history['best_params']}, 耗時={history['iteration_time']:.2f} 秒\")\n",
    "        return self\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100, 500, 1000],\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "adaptive_search = FastAdaptiveGridSearch(\n",
    "    svm_model, \n",
    "    param_grid, \n",
    "    n_iterations=3\n",
    ")\n",
    "\n",
    "total_train_start = time.time()\n",
    "adaptive_search.fit(X_train_scaled, y_train)\n",
    "total_train_end = time.time()\n",
    "print(f\"\\nSVM自適應網格搜尋總訓練耗時: {total_train_end - total_train_start:.2f} 秒\")\n",
    "\n",
    "# 測試集評估\n",
    "test_start = time.time()\n",
    "y_pred = adaptive_search.best_estimator_.predict(X_test_scaled)\n",
    "test_end = time.time()\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nSVM測試集準確率: {test_acc:.6f} (預測耗時: {test_end - test_start:.2f} 秒)\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自適應網格搜尋SVM 測試集 (最終版)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Feature Standardlization...\n",
      "\n",
      "Beginning Adaptive GridSearchCV...\n",
      "\n",
      "iteration 1/3\n",
      "Current parameter grid: {'C': [1, 10, 100, 500, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['rbf']}\n",
      "iteration 1 Best parameter: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "iteration 1 Best grade: 0.999669\n",
      "iteration 1 Execution time: 1677.54 sec\n",
      "\n",
      "iteration 2/3\n",
      "Current parameter grid: {'C': [7.94328235, 89.12509381, 1000.0], 'gamma': [0.0001, 0.00316228, 0.1], 'kernel': ['rbf']}\n",
      "iteration 2 Best parameter: {'C': 1000.0, 'gamma': 0.00316228, 'kernel': 'rbf'}\n",
      "iteration 2 Best grade: 0.999634\n",
      "iteration 2 Execution time: 677.17 sec\n",
      "\n",
      "iteration 3/3\n",
      "Current parameter grid: {'C': [184.07720017, 429.04218926, 1000.0], 'gamma': [0.00028184, 0.00316228, 0.03548137], 'kernel': ['rbf']}\n",
      "iteration 3 Best parameter: {'C': 1000.0, 'gamma': 0.03548137, 'kernel': 'rbf'}\n",
      "iteration 3 Best grade: 0.999685\n",
      "iteration 3 Execution time: 1713.70 sec\n",
      "\n",
      "Adaptive GridSearchCV completed !\n",
      "Total execution time: 4068.40 sec\n",
      "Final best parameter: {'C': 1000.0, 'gamma': 0.03548137, 'kernel': 'rbf'}\n",
      "Final best grade: 0.999685\n",
      "\n",
      "The history of optimized parameter:\n",
      "iteration 1: grade=0.999669, parameter={'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}, execution time=1677.54 sec\n",
      "iteration 2: grade=0.999634, parameter={'C': 1000.0, 'gamma': 0.00316228, 'kernel': 'rbf'}, execution time=677.17 sec\n",
      "iteration 3: grade=0.999685, parameter={'C': 1000.0, 'gamma': 0.03548137, 'kernel': 'rbf'}, execution time=1713.70 sec\n",
      "\n",
      "SVM adaptive gridsearchCV total execution time: 4068.40 sec\n",
      "\n",
      "SVM testing accuracy: 0.998700 (execution time: 23.52 sec)\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       1.00      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "Confusion Matrix:\n",
      " [[49669    94]\n",
      " [    4 25616]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 載入資料\n",
    "print(\"Loading data...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "print(\"Feature Standardlization...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 改良後的自適應搜尋\n",
    "class LogRefinedAdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        new_param_grid = {}\n",
    "        for param_name, values in param_grid.items():\n",
    "            if isinstance(values[0], str):\n",
    "                new_param_grid[param_name] = values\n",
    "                continue\n",
    "            best_val = best_params[param_name]\n",
    "            log_vals = np.log10(values)\n",
    "            log_best = np.log10(best_val)\n",
    "            shrink = 0.7 / (iteration + 1)\n",
    "            log_range = max(log_vals) - min(log_vals)\n",
    "            delta = log_range * shrink\n",
    "            lower = max(log_best - delta, min(log_vals))\n",
    "            upper = min(log_best + delta, max(log_vals))\n",
    "            new_logs = np.linspace(lower, upper, 3)\n",
    "            new_vals = sorted(set([round(float(10**v), 8) for v in new_logs]))\n",
    "            new_param_grid[param_name] = new_vals\n",
    "        return new_param_grid\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "        print(\"\\nBeginning Adaptive GridSearchCV...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            cv_fold = 2 if i < self.n_iterations - 1 else 5 \n",
    "            print(f\"\\niteration {i+1}/{self.n_iterations}\")\n",
    "            print(f\"Current parameter grid: {current_param_grid}\")\n",
    "            iter_start = time.time()\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_param_grid, \n",
    "                cv=cv_fold, \n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "            iter_end = time.time()\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            print(f\"iteration {i+1} Best parameter: {iteration_best_params}\")\n",
    "            print(f\"iteration {i+1} Best grade: {iteration_best_score:.6f}\")\n",
    "            print(f\"iteration {i+1} Execution time: {iter_end - iter_start:.2f} sec\")\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score,\n",
    "                'iteration_time': iter_end - iter_start\n",
    "            })\n",
    "            if iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = grid_search.best_estimator_\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    iteration_best_params, \n",
    "                    current_param_grid,\n",
    "                    i\n",
    "                )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\nAdaptive GridSearchCV completed !\")\n",
    "        print(f\"Total execution time: {elapsed_time:.2f} sec\")\n",
    "        print(f\"Final best parameter: {self.best_params_}\")\n",
    "        print(f\"Final best grade: {self.best_score_:.6f}\")\n",
    "        print(\"\\nThe history of optimized parameter:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"iteration {history['iteration']}: grade={history['best_score']:.6f}, parameter={history['best_params']}, execution time={history['iteration_time']:.2f} sec\")\n",
    "        return self\n",
    "\n",
    "# 初始化與執行\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100, 500, 1000],\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "adaptive_search = LogRefinedAdaptiveGridSearch(\n",
    "    svm_model,\n",
    "    param_grid,\n",
    "    n_iterations=3\n",
    ")\n",
    "\n",
    "total_train_start = time.time()\n",
    "adaptive_search.fit(X_train_scaled, y_train)\n",
    "total_train_end = time.time()\n",
    "print(f\"\\nSVM adaptive gridsearchCV total execution time: {total_train_end - total_train_start:.2f} sec\")\n",
    "\n",
    "# 測試集評估\n",
    "test_start = time.time()\n",
    "y_pred = adaptive_search.best_estimator_.predict(X_test_scaled)\n",
    "test_end = time.time()\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nSVM testing accuracy: {test_acc:.6f} (execution time: {test_end - test_start:.2f} sec)\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入資料...\n",
      "特徵標準化...\n",
      "\n",
      "開始自適應參數範圍優化...\n",
      "當前參數搜索範圍: {'C': [1, 10, 100, 500, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['rbf']}\n",
      "迭代 1 最佳參數: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "迭代 1 最佳分數: 0.999685\n",
      "迭代 1 耗時: 3245.73 秒\n",
      "當前參數搜索範圍: {'C': [63.09573445, 158.48931925, 398.10717055, 1000.0], 'gamma': [0.00063096, 0.00341455, 0.0184785, 0.1], 'kernel': ['rbf']}\n",
      "迭代 2 最佳參數: {'C': 1000.0, 'gamma': 0.00341455, 'kernel': 'rbf'}\n",
      "迭代 2 最佳分數: 0.999688\n",
      "迭代 2 耗時: 1546.76 秒\n",
      "當前參數搜索範圍: {'C': [515.22864459, 642.68771732, 801.67806339, 1000.0], 'gamma': [0.00101236, 0.00227685, 0.00512075, 0.01151683], 'kernel': ['rbf']}\n",
      "迭代 3 最佳參數: {'C': 1000.0, 'gamma': 0.00512075, 'kernel': 'rbf'}\n",
      "迭代 3 最佳分數: 0.999691\n",
      "迭代 3 耗時: 600.03 秒\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "總耗時: 5392.52 秒\n",
      "最終最佳參數: {'C': 1000.0, 'gamma': 0.00512075, 'kernel': 'rbf'}\n",
      "最終最佳分數: 0.999691\n",
      "\n",
      "參數優化歷史:\n",
      "迭代 1: 分數=0.999685, 參數={'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}, 耗時=3245.73 秒\n",
      "迭代 2: 分數=0.999688, 參數={'C': 1000.0, 'gamma': 0.00341455, 'kernel': 'rbf'}, 耗時=1546.76 秒\n",
      "迭代 3: 分數=0.999691, 參數={'C': 1000.0, 'gamma': 0.00512075, 'kernel': 'rbf'}, 耗時=600.03 秒\n",
      "\n",
      "SVM自適應網格搜尋總訓練耗時: 5392.52 秒\n",
      "\n",
      "SVM測試集準確率: 0.997015 (預測耗時: 11.87 秒)\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       0.99      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "Confusion Matrix:\n",
      " [[49542   221]\n",
      " [    4 25616]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 載入資料\n",
    "print(\"載入資料...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "print(\"特徵標準化...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 改良後的自適應搜尋\n",
    "class LogRefinedAdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        new_param_grid = {}\n",
    "        shrink_factor = 0.6 / (iteration + 1.5)  # 調整縮減因子，早期更快收斂\n",
    "        for param_name, values in param_grid.items():\n",
    "            if isinstance(values[0], str):\n",
    "                new_param_grid[param_name] = values\n",
    "                continue\n",
    "            best_val = best_params[param_name]\n",
    "            log_vals = np.log10(values)\n",
    "            log_best = np.log10(best_val)\n",
    "            log_range = max(log_vals) - min(log_vals)\n",
    "            delta = log_range * shrink_factor\n",
    "            lower = max(log_best - delta, min(log_vals))\n",
    "            upper = min(log_best + delta, max(log_vals))\n",
    "            new_logs = np.linspace(lower, upper, 4)  # 增加到 4 個點，提升精細度\n",
    "            new_vals = sorted(set([round(float(10**v), 8) for v in new_logs]))\n",
    "            new_param_grid[param_name] = new_vals\n",
    "        return new_param_grid\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "        print(\"\\n開始自適應參數範圍優化...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            cv_fold = 3  # 統一使用 3 折交叉驗證\n",
    "            # print(f\"\\n迭代 {i+1}/{self.n_iterations} (CV folds: {cv_fold})\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "            iter_start = time.time()\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator,\n",
    "                current_param_grid,\n",
    "                cv=cv_fold,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                error_score='raise'  # 提高錯誤敏感度\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "            iter_end = time.time()\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "            print(f\"迭代 {i+1} 耗時: {iter_end - iter_start:.2f} 秒\")\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score,\n",
    "                'iteration_time': iter_end - iter_start\n",
    "            })\n",
    "            if iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = grid_search.best_estimator_\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    iteration_best_params,\n",
    "                    current_param_grid,\n",
    "                    i\n",
    "                )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"總耗時: {elapsed_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        print(\"\\n參數優化歷史:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"迭代 {history['iteration']}: 分數={history['best_score']:.6f}, 參數={history['best_params']}, 耗時={history['iteration_time']:.2f} 秒\")\n",
    "        return self\n",
    "\n",
    "# 初始化與執行\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100, 500, 1000],  # 保留原始範圍\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],  # 保留原始範圍\n",
    "    'kernel': ['rbf']  # 保留原始範圍\n",
    "}\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "adaptive_search = LogRefinedAdaptiveGridSearch(\n",
    "    svm_model,\n",
    "    param_grid,\n",
    "    n_iterations=3  # 保留原始迭代次數\n",
    ")\n",
    "\n",
    "total_train_start = time.time()\n",
    "adaptive_search.fit(X_train_scaled, y_train)\n",
    "total_train_end = time.time()\n",
    "print(f\"\\nSVM自適應網格搜尋總訓練耗時: {total_train_end - total_train_start:.2f} 秒\")\n",
    "\n",
    "# 測試集評估\n",
    "test_start = time.time()\n",
    "y_pred = adaptive_search.best_estimator_.predict(X_test_scaled)\n",
    "test_end = time.time()\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nSVM測試集準確率: {test_acc:.6f} (預測耗時: {test_end - test_start:.2f} 秒)\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入資料...\n",
      "特徵標準化...\n",
      "\n",
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數搜索範圍: {'C': [1, 10, 100, 500, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['rbf']}\n",
      "迭代 1 最佳參數: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "迭代 1 最佳分數: 0.999669\n",
      "迭代 1 耗時: 1649.69 秒\n",
      "\n",
      "迭代 2/3\n",
      "當前參數搜索範圍: {'C': [7.94328235, 89.12509381, 1000.0], 'gamma': [0.0001, 0.00316228, 0.1], 'kernel': ['rbf']}\n",
      "迭代 2 最佳參數: {'C': 1000.0, 'gamma': 0.00316228, 'kernel': 'rbf'}\n",
      "迭代 2 最佳分數: 0.999696\n",
      "迭代 2 耗時: 2030.90 秒\n",
      "\n",
      "迭代 3/3\n",
      "當前參數搜索範圍: {'C': [184.07720017, 429.04218926, 1000.0], 'gamma': [0.00028184, 0.00316228, 0.03548137], 'kernel': ['rbf']}\n",
      "迭代 3 最佳參數: {'C': 1000.0, 'gamma': 0.03548137, 'kernel': 'rbf'}\n",
      "迭代 3 最佳分數: 0.999685\n",
      "迭代 3 耗時: 1648.94 秒\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "總耗時: 5329.54 秒\n",
      "最終最佳參數: {'C': 1000.0, 'gamma': 0.00316228, 'kernel': 'rbf'}\n",
      "最終最佳分數: 0.999696\n",
      "\n",
      "參數優化歷史:\n",
      "迭代 1: 分數=0.999669, 參數={'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}, 耗時=1649.69 秒\n",
      "迭代 2: 分數=0.999696, 參數={'C': 1000.0, 'gamma': 0.00316228, 'kernel': 'rbf'}, 耗時=2030.90 秒\n",
      "迭代 3: 分數=0.999685, 參數={'C': 1000.0, 'gamma': 0.03548137, 'kernel': 'rbf'}, 耗時=1648.94 秒\n",
      "\n",
      "SVM自適應網格搜尋總訓練耗時: 5329.54 秒\n",
      "\n",
      "SVM測試集準確率: 0.996790 (預測耗時: 12.05 秒)\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       0.99      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "Confusion Matrix:\n",
      " [[49525   238]\n",
      " [    4 25616]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 載入資料\n",
    "print(\"載入資料...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "print(\"特徵標準化...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class LogRefinedAdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        new_param_grid = {}\n",
    "        for param_name, values in param_grid.items():\n",
    "            if isinstance(values[0], str):\n",
    "                new_param_grid[param_name] = values\n",
    "                continue\n",
    "            best_val = best_params[param_name]\n",
    "            log_vals = np.log10(values)\n",
    "            log_best = np.log10(best_val)\n",
    "            shrink = 0.7 / (iteration + 1)\n",
    "            log_range = max(log_vals) - min(log_vals)\n",
    "            delta = log_range * shrink\n",
    "            lower = max(log_best - delta, min(log_vals))\n",
    "            upper = min(log_best + delta, max(log_vals))\n",
    "            new_logs = np.linspace(lower, upper, 3)\n",
    "            new_vals = sorted(set([round(float(10**v), 8) for v in new_logs]))\n",
    "            new_param_grid[param_name] = new_vals\n",
    "        return new_param_grid\n",
    "\n",
    "    def _get_cv_folds(self, iteration):\n",
    "        \"\"\"根據迭代次數返回對應的CV折數\"\"\"\n",
    "        if iteration == 0:  # 第一次\n",
    "            return 2\n",
    "        elif iteration == 1:  # 第二次\n",
    "            return 4\n",
    "        else:  # 第三次及以後\n",
    "            return 5\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "        print(\"\\n開始自適應參數範圍優化...\")\n",
    "        for i in range(self.n_iterations): \n",
    "            cv_fold = self._get_cv_folds(i) \n",
    "            \n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\") \n",
    "            # print(f\"CV折數: {cv_fold}\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "            iter_start = time.time()\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_param_grid, \n",
    "                cv=cv_fold, \n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "            iter_end = time.time()\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "            print(f\"迭代 {i+1} 耗時: {iter_end - iter_start:.2f} 秒\")\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score,\n",
    "                'iteration_time': iter_end - iter_start\n",
    "            })\n",
    "            if iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = grid_search.best_estimator_\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    iteration_best_params, \n",
    "                    current_param_grid,\n",
    "                    i\n",
    "                )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"總耗時: {elapsed_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        print(\"\\n參數優化歷史:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"迭代 {history['iteration']}: 分數={history['best_score']:.6f}, 參數={history['best_params']}, 耗時={history['iteration_time']:.2f} 秒\")\n",
    "        return self\n",
    "\n",
    "# 初始化與執行\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100, 500, 1000],\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "adaptive_search = LogRefinedAdaptiveGridSearch(\n",
    "    svm_model,\n",
    "    param_grid,\n",
    "    n_iterations=3\n",
    ")\n",
    "\n",
    "total_train_start = time.time()\n",
    "adaptive_search.fit(X_train_scaled, y_train)\n",
    "total_train_end = time.time()\n",
    "print(f\"\\nSVM自適應網格搜尋總訓練耗時: {total_train_end - total_train_start:.2f} 秒\")\n",
    "\n",
    "# 測試集評估\n",
    "test_start = time.time()\n",
    "y_pred = adaptive_search.best_estimator_.predict(X_test_scaled)\n",
    "test_end = time.time()\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nSVM測試集準確率: {test_acc:.6f} (預測耗時: {test_end - test_start:.2f} 秒)\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入資料...\n",
      "特徵標準化...\n",
      "\n",
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數搜索範圍: {'C': [1, 10, 100, 500, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['rbf']}\n",
      "迭代 1 最佳參數: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "迭代 1 最佳分數: 0.999669\n",
      "迭代 1 耗時: 1721.89 秒\n",
      "\n",
      "迭代 2/3\n",
      "當前參數搜索範圍: {'C': [7.94328235, 89.12509381, 1000.0], 'gamma': [0.0001, 0.00316228, 0.1], 'kernel': ['rbf']}\n",
      "迭代 2 最佳參數: {'C': 1000.0, 'gamma': 0.00316228, 'kernel': 'rbf'}\n",
      "迭代 2 最佳分數: 0.999680\n",
      "迭代 2 耗時: 2378.04 秒\n",
      "\n",
      "迭代 3/3\n",
      "當前參數搜索範圍: {'C': [184.07720017, 429.04218926, 1000.0], 'gamma': [0.00028184, 0.00316228, 0.03548137], 'kernel': ['rbf']}\n",
      "迭代 3 最佳參數: {'C': 1000.0, 'gamma': 0.03548137, 'kernel': 'rbf'}\n",
      "迭代 3 最佳分數: 0.999685\n",
      "迭代 3 耗時: 1701.91 秒\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "總耗時: 5801.85 秒\n",
      "最終最佳參數: {'C': 1000.0, 'gamma': 0.03548137, 'kernel': 'rbf'}\n",
      "最終最佳分數: 0.999685\n",
      "\n",
      "參數優化歷史:\n",
      "迭代 1: 分數=0.999669, 參數={'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}, 耗時=1721.89 秒\n",
      "迭代 2: 分數=0.999680, 參數={'C': 1000.0, 'gamma': 0.00316228, 'kernel': 'rbf'}, 耗時=2378.04 秒\n",
      "迭代 3: 分數=0.999685, 參數={'C': 1000.0, 'gamma': 0.03548137, 'kernel': 'rbf'}, 耗時=1701.91 秒\n",
      "\n",
      "SVM自適應網格搜尋總訓練耗時: 5801.85 秒\n",
      "\n",
      "SVM測試集準確率: 0.998700 (預測耗時: 23.60 秒)\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       1.00      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "Confusion Matrix:\n",
      " [[49669    94]\n",
      " [    4 25616]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 載入資料\n",
    "print(\"載入資料...\")\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "print(\"特徵標準化...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class LogRefinedAdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        new_param_grid = {}\n",
    "        for param_name, values in param_grid.items():\n",
    "            if isinstance(values[0], str):\n",
    "                new_param_grid[param_name] = values\n",
    "                continue\n",
    "            best_val = best_params[param_name]\n",
    "            log_vals = np.log10(values)\n",
    "            log_best = np.log10(best_val)\n",
    "            shrink = 0.7 / (iteration + 1)\n",
    "            log_range = max(log_vals) - min(log_vals)\n",
    "            delta = log_range * shrink\n",
    "            lower = max(log_best - delta, min(log_vals))\n",
    "            upper = min(log_best + delta, max(log_vals))\n",
    "            new_logs = np.linspace(lower, upper, 3)\n",
    "            new_vals = sorted(set([round(float(10**v), 8) for v in new_logs]))\n",
    "            new_param_grid[param_name] = new_vals\n",
    "        return new_param_grid\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "        print(\"\\n開始自適應參數範圍優化...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            # 修改這裡：第一次使用 cv=2，之後使用 cv=5\n",
    "            cv_fold = 2 if i == 0 else 5\n",
    "\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "            iter_start = time.time()\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_param_grid, \n",
    "                cv=cv_fold, \n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "            iter_end = time.time()\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "            print(f\"迭代 {i+1} 耗時: {iter_end - iter_start:.2f} 秒\")\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score,\n",
    "                'iteration_time': iter_end - iter_start\n",
    "            })\n",
    "            if iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = grid_search.best_estimator_\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(\n",
    "                    iteration_best_params, \n",
    "                    current_param_grid,\n",
    "                    i\n",
    "                )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"總耗時: {elapsed_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        print(\"\\n參數優化歷史:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"迭代 {history['iteration']}: 分數={history['best_score']:.6f}, 參數={history['best_params']}, 耗時={history['iteration_time']:.2f} 秒\")\n",
    "        return self\n",
    "\n",
    "# 初始化與執行\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100, 500, 1000],\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "svm_model = SVC(random_state=42)\n",
    "adaptive_search = LogRefinedAdaptiveGridSearch(\n",
    "    svm_model,\n",
    "    param_grid,\n",
    "    n_iterations=3\n",
    ")\n",
    "\n",
    "total_train_start = time.time()\n",
    "adaptive_search.fit(X_train_scaled, y_train)\n",
    "total_train_end = time.time()\n",
    "print(f\"\\nSVM自適應網格搜尋總訓練耗時: {total_train_end - total_train_start:.2f} 秒\")\n",
    "\n",
    "# 測試集評估\n",
    "test_start = time.time()\n",
    "y_pred = adaptive_search.best_estimator_.predict(X_test_scaled)\n",
    "test_end = time.time()\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nSVM測試集準確率: {test_acc:.6f} (預測耗時: {test_end - test_start:.2f} 秒)\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"用tesing data(之前模型都沒有看過的測試資料(資料夾03-11)來個別測試過自適應往格搜尋調整過後的LR模型的測試準確率(模型最終的表現)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數搜索範圍: {'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l2'], 'solver': ['lbfgs']}\n",
      "迭代 1 最佳參數: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "迭代 1 最佳分數: 0.990380\n",
      "迭代 1 測試集準確率: 0.996830\n",
      "\n",
      "迭代 2/3\n",
      "當前參數搜索範圍: {'C': [np.float64(1e-05), np.float64(4.3e-05), np.float64(0.000181), np.float64(0.000769), np.float64(0.003268), np.float64(0.013895), np.float64(0.059078), np.float64(0.251189)], 'penalty': ['l2'], 'solver': ['lbfgs']}\n",
      "迭代 2 最佳參數: {'C': np.float64(0.003268), 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "迭代 2 最佳分數: 0.990632\n",
      "迭代 2 測試集準確率: 0.996776\n",
      "\n",
      "迭代 3/3\n",
      "當前參數搜索範圍: {'C': [np.float64(0.000715), np.float64(0.001104), np.float64(0.001704), np.float64(0.00263), np.float64(0.00406), np.float64(0.006268), np.float64(0.009676), np.float64(0.014938)], 'penalty': ['l2'], 'solver': ['lbfgs']}\n",
      "迭代 3 最佳參數: {'C': np.float64(0.00406), 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "迭代 3 最佳分數: 0.990646\n",
      "迭代 3 測試集準確率: 0.996803\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "最終最佳參數: {'C': np.float64(0.00406), 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "最終最佳分數: 0.990646\n",
      "\n",
      "===== 測試集評估：Logistic Regression (Adaptive) =====\n",
      "Logistic Regression (Adaptive) 測試準確率: 0.996803\n",
      "Logistic Regression (Adaptive) 分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       0.99      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "Logistic Regression (Adaptive) 混淆矩陣:\n",
      "[[49524   239]\n",
      " [    2 25618]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 添加自適應參數範圍優化類\n",
    "class AdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, cv=5, scoring='accuracy', n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.best_estimator_ = None\n",
    "        self.optimization_history = []\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        new_param_grid = {}\n",
    "        shrink_factor = 0.3 / (iteration + 1)\n",
    "\n",
    "        for param_name, param_value in best_params.items():\n",
    "            if param_name not in param_grid or isinstance(param_grid[param_name][0], str):\n",
    "                new_param_grid[param_name] = [param_value]\n",
    "                continue\n",
    "\n",
    "            current_values = param_grid[param_name]\n",
    "            if len(current_values) <= 1:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                idx = current_values.index(param_value)\n",
    "            except ValueError:\n",
    "                idx = min(range(len(current_values)), key=lambda i: abs(current_values[i] - param_value))\n",
    "\n",
    "            param_range = max(current_values) - min(current_values)\n",
    "            delta = param_range * shrink_factor\n",
    "\n",
    "            if param_range < 1e-10:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "\n",
    "            if isinstance(param_value, float):\n",
    "                log_min = np.log10(min(current_values))\n",
    "                log_max = np.log10(max(current_values))\n",
    "                log_val = np.log10(param_value)\n",
    "                log_delta = (log_max - log_min) * shrink_factor\n",
    "                log_lower = max(log_val - log_delta, log_min)\n",
    "                log_upper = min(log_val + log_delta, log_max)\n",
    "\n",
    "                new_values = [round(10**x, 6) for x in np.linspace(log_lower, log_upper, 8)]\n",
    "\n",
    "            else:\n",
    "                log_min = np.log10(min(current_values))\n",
    "                log_max = np.log10(max(current_values))\n",
    "                log_val = np.log10(param_value)\n",
    "                log_delta = (log_max - log_min) * shrink_factor\n",
    "                log_lower = max(log_val - log_delta, log_min)\n",
    "                log_upper = min(log_val + log_delta, log_max)\n",
    "\n",
    "                new_values = [round(10 ** x, 6) for x in np.linspace(log_lower, log_upper, 4)]\n",
    "\n",
    "            new_param_grid[param_name] = sorted(list(set(new_values)))\n",
    "\n",
    "        return new_param_grid\n",
    "\n",
    "    def fit(self, X, y, X_test=None, y_test=None):\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "\n",
    "        print(\"開始自適應參數範圍優化...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator,\n",
    "                current_param_grid,\n",
    "                cv=self.cv,\n",
    "                scoring=self.scoring,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            iteration_best_estimator = grid_search.best_estimator_\n",
    "\n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "\n",
    "            # 額外輸出測試集評估\n",
    "            if X_test is not None and y_test is not None:\n",
    "                y_pred = iteration_best_estimator.predict(X_test)\n",
    "                test_acc = accuracy_score(y_test, y_pred)\n",
    "                print(f\"迭代 {i+1} 測試集準確率: {test_acc:.6f}\")\n",
    "\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score\n",
    "            })\n",
    "\n",
    "            if i == 0 or iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = iteration_best_estimator\n",
    "\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(iteration_best_params, current_param_grid, i)\n",
    "\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        return self\n",
    "\n",
    "# 載入資料\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵縮放\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression 的自適應參數優化\n",
    "param_grid_lr = {\n",
    "    'C': [1e-5, 1e-4, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs']\n",
    "}\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "adaptive_search_lr = AdaptiveGridSearch(logreg_model, param_grid_lr, cv=5, scoring='accuracy', n_iterations=3)\n",
    "adaptive_search_lr.fit(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "best_lr_model = adaptive_search_lr.best_estimator_\n",
    "\n",
    "# 模型測試集評估\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    print(f\"{model_name} 測試準確率: {accuracy:.6f}\")\n",
    "    print(f\"{model_name} 分類報告:\\n{classification_report(y_test, y_pred_test)}\")\n",
    "    print(f\"{model_name} 混淆矩陣:\\n{confusion_matrix(y_test, y_pred_test)}\")\n",
    "\n",
    "print(\"\\n===== 測試集評估：Logistic Regression (Adaptive) =====\")\n",
    "evaluate_model(best_lr_model, X_test_scaled, y_test, \"Logistic Regression (Adaptive)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最終LR自適應結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin LR model adaptive gridsearchCV...\n",
      "\n",
      "iteration 1/3\n",
      "current grid: {'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l2'], 'solver': ['lbfgs']}\n",
      "iteration 1 best parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "iteration 1 best grade: 0.990543\n",
      "iteration 1 execution time: 6.84 秒\n",
      "\n",
      "iteration 2/3\n",
      "current grid: {'C': [0.001, 0.01, 0.1], 'penalty': ['l2'], 'solver': ['lbfgs']}\n",
      "iteration 2 best parameter: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "iteration 2 best grade: 0.990543\n",
      "iteration 2 execution time: 3.50 秒\n",
      "\n",
      "iteration 3/3\n",
      "current grid: {'C': [0.001, 0.01, 0.1], 'penalty': ['l2'], 'solver': ['lbfgs']}\n",
      "iteration 3 best parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "iteration 3 best grade: 0.990380\n",
      "iteration 3 execution time: 5.83 秒\n",
      "\n",
      "total execution time: 16.16 秒\n",
      "final best parameter: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "final best grade: 0.990380\n",
      "\n",
      "the history of optimized parameter:\n",
      "iteration 1: grade=0.990543, parameter={'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}, execution time=6.84 sec\n",
      "iteration 2: grade=0.990543, parameter={'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}, execution time=3.50 sec\n",
      "iteration 3: grade=0.990380, parameter={'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}, execution time=5.83 sec\n",
      "\n",
      "Logistic Regression (Adaptive) testing accuracy: 0.996830\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       0.99      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "confusion_matrix:\n",
      "[[49526   237]\n",
      " [    2 25618]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 載入資料\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class FastAdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "        self.allowed_C = param_grid['C']\n",
    "\n",
    "    def _get_neighbor_C(self, best_C):\n",
    "        idx = self.allowed_C.index(best_C)\n",
    "        neighbors = []\n",
    "        if idx > 0:\n",
    "            neighbors.append(self.allowed_C[idx-1])\n",
    "        neighbors.append(best_C)\n",
    "        if idx < len(self.allowed_C)-1:\n",
    "            neighbors.append(self.allowed_C[idx+1])\n",
    "        return sorted(list(set(neighbors)))\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params):\n",
    "        new_grid = {}\n",
    "        # 只取最佳C的左右各一個\n",
    "        if 'C' in best_params:\n",
    "            best_C = best_params['C']\n",
    "            new_grid['C'] = self._get_neighbor_C(best_C)\n",
    "        for param in ['penalty', 'solver']:\n",
    "            if param in best_params:\n",
    "                new_grid[param] = [best_params[param]]\n",
    "        return new_grid\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_grid = self.initial_param_grid\n",
    "        print(\"begin LR model adaptive gridsearchCV...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            cv = 2 if i < self.n_iterations - 1 else 5  # 前兩輪2折，最後一輪5折\n",
    "            print(f\"\\niteration {i+1}/{self.n_iterations}\")\n",
    "            print(f\"current grid: {current_grid}\")\n",
    "            gs = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_grid, \n",
    "                cv=cv, \n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                error_score='raise'\n",
    "            )\n",
    "            iter_start = time.time()\n",
    "            gs.fit(X, y)\n",
    "            iter_time = time.time() - iter_start\n",
    "            self.best_params_ = gs.best_params_\n",
    "            self.best_estimator_ = gs.best_estimator_\n",
    "            self.best_score_ = gs.best_score_\n",
    "            print(f\"iteration {i+1} best parameter: {self.best_params_}\")\n",
    "            print(f\"iteration {i+1} best grade: {self.best_score_:.6f}\")\n",
    "            print(f\"iteration {i+1} execution time: {iter_time:.2f} 秒\")\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_grid,\n",
    "                'best_params': self.best_params_,\n",
    "                'best_score': self.best_score_,\n",
    "                'iteration_time': iter_time\n",
    "            })\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_grid = self._generate_new_param_grid(self.best_params_)\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\ntotal execution time: {total_time:.2f} 秒\")\n",
    "        print(f\"final best parameter: {self.best_params_}\")\n",
    "        print(f\"final best grade: {self.best_score_:.6f}\")\n",
    "        print(\"\\nthe history of optimized parameter:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"iteration {history['iteration']}: grade={history['best_score']:.6f}, parameter={history['best_params']}, execution time={history['iteration_time']:.2f} sec\")\n",
    "        return self\n",
    "\n",
    "# 與GridSearch相同的初始參數範圍\n",
    "param_grid_lr = {\n",
    "    'C': [1e-5, 1e-4, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "fast_searcher = FastAdaptiveGridSearch(logreg_model, param_grid_lr, n_iterations=3)\n",
    "fast_searcher.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 測試集評估\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    infer_time = time.time() - start\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n{model_name} testing accuracy: {acc:.6f}\")\n",
    "    print(f\"classification_report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    print(f\"confusion_matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "evaluate_model(fast_searcher.best_estimator_, X_test_scaled, y_test, \"Logistic Regression (Adaptive)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"用tesing data(之前模型都沒有看過的測試資料(資料夾03-11)來個別測試過自適應往格搜尋調整過後的KNN模型的測試準確率(模型最終的表現)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始自適應參數範圍優化...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數搜索範圍: {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance'], 'p': [1, 2]}\n",
      "迭代 1 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 1 最佳分數: 0.999799\n",
      "迭代 1 測試集準確率: 0.998395\n",
      "\n",
      "迭代 2/3\n",
      "當前參數搜索範圍: {'n_neighbors': [3, 4, 5, 6, 7], 'p': [1], 'weights': ['distance']}\n",
      "迭代 2 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 2 最佳分數: 0.999799\n",
      "迭代 2 測試集準確率: 0.998395\n",
      "\n",
      "迭代 3/3\n",
      "當前參數搜索範圍: {'n_neighbors': [3, 4], 'p': [1], 'weights': ['distance']}\n",
      "迭代 3 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 3 最佳分數: 0.999799\n",
      "迭代 3 測試集準確率: 0.998395\n",
      "\n",
      "自適應參數範圍優化完成!\n",
      "最終最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "最終最佳分數: 0.999799\n",
      "\n",
      "===== 測試集評估：KNN (Adaptive) =====\n",
      "KNN (Adaptive) 測試準確率: 0.998395\n",
      "KNN (Adaptive) 分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       1.00      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "KNN (Adaptive) 混淆矩陣:\n",
      "[[49644   119]\n",
      " [    2 25618]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 自適應網格搜尋器（與你提供的版本一致）\n",
    "class AdaptiveGridSearch:\n",
    "    def __init__(self, estimator, param_grid, cv=5, scoring='accuracy', n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.best_estimator_ = None\n",
    "        self.optimization_history = []\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, param_grid, iteration):\n",
    "        new_param_grid = {}\n",
    "        shrink_factor = 0.5 / (iteration + 1)\n",
    "\n",
    "        for param_name, param_value in best_params.items():\n",
    "            if param_name not in param_grid or isinstance(param_grid[param_name][0], str):\n",
    "                new_param_grid[param_name] = [param_value]\n",
    "                continue\n",
    "\n",
    "            current_values = param_grid[param_name]\n",
    "            if len(current_values) <= 1:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                idx = current_values.index(param_value)\n",
    "            except ValueError:\n",
    "                idx = min(range(len(current_values)), key=lambda i: abs(current_values[i] - param_value))\n",
    "\n",
    "            param_range = max(current_values) - min(current_values)\n",
    "            delta = param_range * shrink_factor\n",
    "\n",
    "            if param_range < 1e-10:\n",
    "                new_param_grid[param_name] = current_values\n",
    "                continue\n",
    "\n",
    "            if isinstance(param_value, int):\n",
    "                lower = max(int(param_value - delta), min(current_values))\n",
    "                upper = min(int(param_value + delta), max(current_values))\n",
    "                if lower == upper:\n",
    "                    new_values = [lower]\n",
    "                else:\n",
    "                    step = max(1, (upper - lower) // 3)\n",
    "                    new_values = list(range(lower, upper + 1, step))\n",
    "            else:\n",
    "                lower = max(param_value - delta, min(current_values))\n",
    "                upper = min(param_value + delta, max(current_values))\n",
    "                step = (upper - lower) / 3\n",
    "                new_values = [round(lower + i * step, 6) for i in range(4)]\n",
    "\n",
    "            new_param_grid[param_name] = sorted(list(set(new_values)))\n",
    "\n",
    "        return new_param_grid\n",
    "\n",
    "    def fit(self, X, y, X_test=None, y_test=None):\n",
    "        start_time = time.time()\n",
    "        current_param_grid = self.initial_param_grid\n",
    "\n",
    "        print(\"開始自適應參數範圍優化...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數搜索範圍: {current_param_grid}\")\n",
    "\n",
    "            grid_search = GridSearchCV(\n",
    "                self.estimator,\n",
    "                current_param_grid,\n",
    "                cv=self.cv,\n",
    "                scoring=self.scoring,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            grid_search.fit(X, y)\n",
    "\n",
    "            iteration_best_params = grid_search.best_params_\n",
    "            iteration_best_score = grid_search.best_score_\n",
    "            iteration_best_estimator = grid_search.best_estimator_\n",
    "\n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "\n",
    "            if X_test is not None and y_test is not None:\n",
    "                y_pred = iteration_best_estimator.predict(X_test)\n",
    "                test_acc = accuracy_score(y_test, y_pred)\n",
    "                print(f\"迭代 {i+1} 測試集準確率: {test_acc:.6f}\")\n",
    "\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_param_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score\n",
    "            })\n",
    "\n",
    "            if i == 0 or iteration_best_score > self.best_score_:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = iteration_best_estimator\n",
    "\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_param_grid = self._generate_new_param_grid(iteration_best_params, current_param_grid, i)\n",
    "\n",
    "        print(\"\\n自適應參數範圍優化完成!\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        return self\n",
    "\n",
    "# 載入資料\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵縮放\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 自適應 KNN 模型設定與訓練\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1: 曼哈頓距離, 2: 歐幾里得距離\n",
    "}\n",
    "knn_model = KNeighborsClassifier()\n",
    "adaptive_search_knn = AdaptiveGridSearch(knn_model, param_grid_knn, cv=5, scoring='accuracy', n_iterations=3)\n",
    "adaptive_search_knn.fit(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "best_knn_model = adaptive_search_knn.best_estimator_\n",
    "\n",
    "# 測試集模型評估函式\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    print(f\"{model_name} 測試準確率: {accuracy:.6f}\")\n",
    "    print(f\"{model_name} 分類報告:\\n{classification_report(y_test, y_pred_test)}\")\n",
    "    print(f\"{model_name} 混淆矩陣:\\n{confusion_matrix(y_test, y_pred_test)}\")\n",
    "\n",
    "# 模型測試集評估\n",
    "print(\"\\n===== 測試集評估：KNN (Adaptive) =====\")\n",
    "evaluate_model(best_knn_model, X_test_scaled, y_test, \"KNN (Adaptive)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始急速版KNN參數搜索...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數網格: {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance'], 'p': [1, 2]}\n",
      "迭代 1 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 1 最佳分數: 0.999704\n",
      "迭代 1 耗時: 3172.29 秒\n",
      "\n",
      "迭代 2/3\n",
      "當前參數網格: {'n_neighbors': [3, 5], 'weights': ['distance'], 'p': [1]}\n",
      "迭代 2 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 2 最佳分數: 0.999704\n",
      "迭代 2 耗時: 2023.16 秒\n",
      "\n",
      "迭代 3/3\n",
      "當前參數網格: {'n_neighbors': [3, 5], 'weights': ['distance'], 'p': [1]}\n",
      "迭代 3 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 3 最佳分數: 0.999799\n",
      "迭代 3 耗時: 1311.95 秒\n",
      "\n",
      "總耗時: 6507.43 秒\n",
      "最終最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "最終最佳分數: 0.999799\n",
      "\n",
      "參數優化歷史:\n",
      "迭代 1: 分數=0.999704, 參數={'n_neighbors': 3, 'p': 1, 'weights': 'distance'}, 耗時=3172.29 秒\n",
      "迭代 2: 分數=0.999704, 參數={'n_neighbors': 3, 'p': 1, 'weights': 'distance'}, 耗時=2023.16 秒\n",
      "迭代 3: 分數=0.999799, 參數={'n_neighbors': 3, 'p': 1, 'weights': 'distance'}, 耗時=1311.95 秒\n",
      "\n",
      "KNN (急速版) 測試準確率: 0.998395\n",
      "推理耗時: 122.87 秒\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       1.00      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "混淆矩陣:\n",
      "[[49644   119]\n",
      " [    2 25618]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 載入資料\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class FastAdaptiveKNN:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "        self.allowed_k = sorted(param_grid['n_neighbors'])\n",
    "\n",
    "    def _get_neighbor_k(self, best_k):\n",
    "        idx = self.allowed_k.index(best_k)\n",
    "        neighbors = []\n",
    "        if idx > 0:\n",
    "            neighbors.append(self.allowed_k[idx-1])\n",
    "        neighbors.append(best_k)\n",
    "        if idx < len(self.allowed_k)-1:\n",
    "            neighbors.append(self.allowed_k[idx+1])\n",
    "        return sorted(list(set(neighbors)))\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params):\n",
    "        new_grid = {}\n",
    "        # 只取最佳k的左右鄰居\n",
    "        if 'n_neighbors' in best_params:\n",
    "            best_k = best_params['n_neighbors']\n",
    "            new_grid['n_neighbors'] = self._get_neighbor_k(best_k)\n",
    "        # weights和p維持最佳\n",
    "        for param in ['weights', 'p']:\n",
    "            if param in best_params:\n",
    "                new_grid[param] = [best_params[param]]\n",
    "        return new_grid\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_grid = self.initial_param_grid\n",
    "        print(\"開始急速版KNN參數搜索...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            cv = 2 if i < self.n_iterations - 1 else 5\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數網格: {current_grid}\")\n",
    "            gs = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_grid, \n",
    "                cv=cv, \n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                error_score='raise'\n",
    "            )\n",
    "            iter_start = time.time()\n",
    "            gs.fit(X, y)\n",
    "            iter_time = time.time() - iter_start\n",
    "            self.best_params_ = gs.best_params_\n",
    "            self.best_estimator_ = gs.best_estimator_\n",
    "            self.best_score_ = gs.best_score_\n",
    "            print(f\"迭代 {i+1} 最佳參數: {self.best_params_}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {self.best_score_:.6f}\")\n",
    "            print(f\"迭代 {i+1} 耗時: {iter_time:.2f} 秒\")\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_grid,\n",
    "                'best_params': self.best_params_,\n",
    "                'best_score': self.best_score_,\n",
    "                'iteration_time': iter_time\n",
    "            })\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_grid = self._generate_new_param_grid(self.best_params_)\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\n總耗時: {total_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        print(\"\\n參數優化歷史:\")\n",
    "        for history in self.optimization_history:\n",
    "            print(f\"迭代 {history['iteration']}: 分數={history['best_score']:.6f}, 參數={history['best_params']}, 耗時={history['iteration_time']:.2f} 秒\")\n",
    "        return self\n",
    "\n",
    "# 初始參數範圍與你GridSearch相同\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "fast_knn_search = FastAdaptiveKNN(knn_model, param_grid_knn, n_iterations=3)\n",
    "fast_knn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 測試集評估\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    infer_time = time.time() - start\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n{model_name} 測試準確率: {acc:.6f}\")\n",
    "    print(f\"推理耗時: {infer_time:.2f} 秒\")\n",
    "    print(f\"分類報告:\\n{classification_report(y_test, y_pred)}\")\n",
    "    print(f\"混淆矩陣:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "evaluate_model(fast_knn_search.best_estimator_, X_test_scaled, y_test, \"KNN (急速版)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最終版KNN自適應結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始自適應版KNN參數搜索...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數網格: {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance'], 'p': [1, 2]}\n",
      "迭代 1 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 1 最佳分數: 0.999704\n",
      "迭代 1 耗時: 3128.36 秒\n",
      "\n",
      "迭代 2/3\n",
      "當前參數網格: {'n_neighbors': [3, 5], 'weights': ['distance'], 'p': [1]}\n",
      "迭代 2 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 2 最佳分數: 0.999704\n",
      "迭代 2 耗時: 2027.26 秒\n",
      "\n",
      "迭代 3/3\n",
      "當前參數網格: {'n_neighbors': [3, 5], 'weights': ['distance'], 'p': [1]}\n",
      "迭代 3 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 3 最佳分數: 0.999799\n",
      "迭代 3 耗時: 1299.58 秒\n",
      "\n",
      "總耗時: 6455.22 秒\n",
      "最終最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "最終最佳分數: 0.999799\n",
      "\n",
      "KNN (自適應版) 測試準確率: 0.998395\n",
      "推理耗時: 118.95 秒\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       1.00      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "混淆矩陣:\n",
      "[[49644   119]\n",
      " [    2 25618]]\n",
      "\n",
      "總搜尋耗時: 6455.22 秒\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 載入資料\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class RefinedAdaptiveKNN:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "        self.allowed_k = sorted(param_grid['n_neighbors'])\n",
    "\n",
    "    def _get_refined_k_range(self, best_k):\n",
    "        min_k = max(min(self.allowed_k), best_k - 2)\n",
    "        max_k = min(max(self.allowed_k), best_k + 2)\n",
    "        return sorted(list(set([k for k in range(min_k, max_k + 1)]).intersection(self.allowed_k)))\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params):\n",
    "        new_grid = {}\n",
    "        if 'n_neighbors' in best_params:\n",
    "            best_k = best_params['n_neighbors']\n",
    "            new_grid['n_neighbors'] = self._get_refined_k_range(best_k)\n",
    "        for param in ['weights', 'p']:\n",
    "            if param in best_params:\n",
    "                new_grid[param] = [best_params[param]]\n",
    "        return new_grid\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_grid = self.initial_param_grid\n",
    "        print(\"開始自適應版KNN參數搜索...\")\n",
    "        for i in range(self.n_iterations):\n",
    "            cv = 2 if i < self.n_iterations - 1 else 5\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數網格: {current_grid}\")\n",
    "            gs = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_grid, \n",
    "                cv=cv, \n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                error_score='raise'\n",
    "            )\n",
    "            iter_start = time.time()\n",
    "            gs.fit(X, y)\n",
    "            iter_time = time.time() - iter_start\n",
    "            self.best_params_ = gs.best_params_\n",
    "            self.best_estimator_ = gs.best_estimator_\n",
    "            self.best_score_ = gs.best_score_\n",
    "            print(f\"迭代 {i+1} 最佳參數: {self.best_params_}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {self.best_score_:.6f}\")\n",
    "            print(f\"迭代 {i+1} 耗時: {iter_time:.2f} 秒\")\n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_grid,\n",
    "                'best_params': self.best_params_,\n",
    "                'best_score': self.best_score_,\n",
    "                'iteration_time': iter_time\n",
    "            })\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_grid = self._generate_new_param_grid(self.best_params_)\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\n總耗時: {total_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        return self, total_time\n",
    "\n",
    "# 初始參數範圍與一般 GridSearch 相同\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "refined_knn_search = RefinedAdaptiveKNN(knn_model, param_grid_knn, n_iterations=3)\n",
    "refined_knn_search, total_duration = refined_knn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 測試集評估\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    infer_time = time.time() - start\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n{model_name} 測試準確率: {acc:.6f}\")\n",
    "    print(f\"推理耗時: {infer_time:.2f} 秒\")\n",
    "    print(f\"分類報告:\\n{classification_report(y_test, y_pred)}\")\n",
    "    print(f\"混淆矩陣:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "    return acc\n",
    "\n",
    "evaluate_model(refined_knn_search.best_estimator_, X_test_scaled, y_test, \"KNN (自適應版)\")\n",
    "print(f\"\\n總搜尋耗時: {total_duration:.2f} 秒\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自適應網格搜尋的KNN 測試集(最終版)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始自適應KNN參數搜索...\n",
      "\n",
      "迭代 1/3\n",
      "當前參數網格: {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance'], 'p': [1, 2]}\n",
      "迭代 1 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 1 最佳分數: 0.999140\n",
      "迭代 1 耗時: 88.77 秒\n",
      "\n",
      "迭代 2/3\n",
      "當前參數網格: {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance'], 'p': [1, 2]}\n",
      "迭代 2 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 2 最佳分數: 0.999140\n",
      "迭代 2 耗時: 84.65 秒\n",
      "\n",
      "迭代 3/3\n",
      "當前參數網格: {'n_neighbors': [3, 5], 'weights': ['distance', 'uniform'], 'p': [1, 2]}\n",
      "迭代 3 最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "迭代 3 最佳分數: 0.999797\n",
      "迭代 3 耗時: 2039.72 秒\n",
      "\n",
      "總耗時: 2213.50 秒\n",
      "最終最佳參數: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "最終最佳分數: 0.999797\n",
      "\n",
      "優化歷史摘要:\n",
      "迭代1: 樣本數=50000, 參數數量=20, 分數=0.999140, 耗時=88.77s\n",
      "迭代2: 樣本數=50000, 參數數量=20, 分數=0.999140, 耗時=84.65s\n",
      "迭代3: 樣本數=368604, 參數數量=8, 分數=0.999797, 耗時=2039.72s\n",
      "\n",
      "KNN (自適應) 測試準確率: 0.998395\n",
      "推理耗時: 121.35 秒\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       1.00      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "混淆矩陣:\n",
      "[[49644   119]\n",
      " [    2 25618]]\n",
      "\n",
      "總搜尋耗時: 2213.50 秒\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 載入資料\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class OptimizedRefinedAdaptiveKNN:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "        self.allowed_k = sorted(param_grid['n_neighbors'])\n",
    "        \n",
    "        # 預先計算用於抽樣的索引 - 針對大型數據集進行優化\n",
    "        self.sample_size = min(50000, len(X_train_scaled))  # 限制樣本大小以加速搜索\n",
    "        \n",
    "    def _get_refined_k_range(self, best_k, iteration):\n",
    "        \"\"\"動態調整k的搜索範圍，隨迭代變得更精細\"\"\"\n",
    "        if iteration == 0:\n",
    "            # 第一次迭代：保持原始範圍\n",
    "            return self.allowed_k\n",
    "        elif iteration == 1:\n",
    "            # 第二次迭代：圍繞最佳k值±2\n",
    "            min_k = max(min(self.allowed_k), best_k - 2)\n",
    "            max_k = min(max(self.allowed_k), best_k + 2)\n",
    "            refined_range = [k for k in self.allowed_k if min_k <= k <= max_k]\n",
    "            return refined_range if refined_range else [best_k]\n",
    "        else:\n",
    "            # 第三次迭代：圍繞最佳k值±1，更精細搜索\n",
    "            min_k = max(min(self.allowed_k), best_k - 1)\n",
    "            max_k = min(max(self.allowed_k), best_k + 1)\n",
    "            refined_range = [k for k in self.allowed_k if min_k <= k <= max_k]\n",
    "            return refined_range if refined_range else [best_k]\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, iteration):\n",
    "        \"\"\"根據迭代次數生成不同精細度的參數網格\"\"\"\n",
    "        new_grid = {}\n",
    "        \n",
    "        # k值範圍調整\n",
    "        if 'n_neighbors' in best_params:\n",
    "            best_k = best_params['n_neighbors']\n",
    "            new_grid['n_neighbors'] = self._get_refined_k_range(best_k, iteration)\n",
    "        \n",
    "        # weights和p參數的策略調整\n",
    "        if iteration == 0:\n",
    "            # 第一次迭代：保持所有選項\n",
    "            for param in ['weights', 'p']:\n",
    "                if param in self.initial_param_grid:\n",
    "                    new_grid[param] = self.initial_param_grid[param]\n",
    "        elif iteration == 1:\n",
    "            # 第二次迭代：基於第一次的結果，但仍保持一定探索性\n",
    "            if 'weights' in best_params:\n",
    "                # 保留最佳weights，但也保留另一個選項進行比較\n",
    "                best_weight = best_params['weights']\n",
    "                other_weights = [w for w in self.initial_param_grid['weights'] if w != best_weight]\n",
    "                new_grid['weights'] = [best_weight] + other_weights[:1]  # 最多保留2個選項\n",
    "            \n",
    "            if 'p' in best_params:\n",
    "                # 對p參數採用類似策略\n",
    "                best_p = best_params['p']\n",
    "                other_p = [p for p in self.initial_param_grid['p'] if p != best_p]\n",
    "                new_grid['p'] = [best_p] + other_p[:1]  # 最多保留2個選項\n",
    "        else:\n",
    "            # 第三次迭代：專注於最佳參數組合的精細調優\n",
    "            for param in ['weights', 'p']:\n",
    "                if param in best_params:\n",
    "                    new_grid[param] = [best_params[param]]\n",
    "        \n",
    "        return new_grid\n",
    "\n",
    "    def _get_sample_indices(self, y, sample_size):\n",
    "        \"\"\"分層抽樣獲取訓練子集，確保類別平衡\"\"\"\n",
    "        if len(y) <= sample_size:\n",
    "            return np.arange(len(y))\n",
    "        \n",
    "        # 使用分層抽樣保持類別比例\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        indices = np.arange(len(y))\n",
    "        sample_indices, _ = train_test_split(\n",
    "            indices, \n",
    "            train_size=sample_size, \n",
    "            stratify=y, \n",
    "            random_state=42\n",
    "        )\n",
    "        return sample_indices\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_grid = self.initial_param_grid\n",
    "        \n",
    "        print(\"開始自適應KNN參數搜索...\")\n",
    "        # print(f\"數據集大小: {X.shape}\")\n",
    "        \n",
    "        # 預先獲取抽樣索引用於前兩次迭代\n",
    "        sample_indices = self._get_sample_indices(y, self.sample_size)\n",
    "        # print(f\"前兩次迭代使用樣本大小: {len(sample_indices)}\")\n",
    "        \n",
    "        for i in range(self.n_iterations):\n",
    "            print(f\"\\n迭代 {i+1}/{self.n_iterations}\")\n",
    "            print(f\"當前參數網格: {current_grid}\")\n",
    "            \n",
    "            # 動態決定使用的數據量和交叉驗證策略\n",
    "            if i < self.n_iterations - 1:\n",
    "                # 前兩次迭代：使用抽樣數據和較少的CV折數\n",
    "                X_iter = X[sample_indices]\n",
    "                y_iter = y.iloc[sample_indices] if hasattr(y, 'iloc') else y[sample_indices]\n",
    "                cv_folds = 3  # 使用3折交叉驗證加速\n",
    "                # print(f\"使用抽樣數據: {X_iter.shape[0]} 樣本, CV折數: {cv_folds}\")\n",
    "            else:\n",
    "                # 最後一次迭代：使用完整數據和標準CV折數\n",
    "                X_iter = X\n",
    "                y_iter = y\n",
    "                cv_folds = 5  # 最後一次使用完整5折交叉驗證確保準確性\n",
    "                # print(f\"使用完整數據: {X_iter.shape[0]} 樣本, CV折數: {cv_folds}\")\n",
    "            \n",
    "            # 使用StratifiedKFold確保類別平衡\n",
    "            skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "            \n",
    "            gs = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_grid, \n",
    "                cv=skf,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                error_score='raise',\n",
    "                verbose=0  # 減少輸出\n",
    "            )\n",
    "            \n",
    "            iter_start = time.time()\n",
    "            gs.fit(X_iter, y_iter)\n",
    "            iter_time = time.time() - iter_start\n",
    "            \n",
    "            # 更新最佳參數\n",
    "            iteration_best_params = gs.best_params_\n",
    "            iteration_best_score = gs.best_score_\n",
    "            \n",
    "            # 如果是最後一次迭代或者分數有提升，更新全局最佳\n",
    "            if i == 0 or iteration_best_score > self.best_score_ or i == self.n_iterations - 1:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                # 使用完整數據訓練最終模型\n",
    "                self.best_estimator_ = self.estimator.set_params(**self.best_params_)\n",
    "                if i < self.n_iterations - 1:\n",
    "                    # 如果不是最後一次迭代，用完整數據重新訓練以獲得更準確的模型\n",
    "                    self.best_estimator_.fit(X, y)\n",
    "                else:\n",
    "                    # 最後一次迭代已經使用完整數據\n",
    "                    self.best_estimator_ = gs.best_estimator_\n",
    "            \n",
    "            print(f\"迭代 {i+1} 最佳參數: {iteration_best_params}\")\n",
    "            print(f\"迭代 {i+1} 最佳分數: {iteration_best_score:.6f}\")\n",
    "            print(f\"迭代 {i+1} 耗時: {iter_time:.2f} 秒\")\n",
    "            \n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score,\n",
    "                'iteration_time': iter_time,\n",
    "                'sample_size': len(y_iter)\n",
    "            })\n",
    "            \n",
    "            # 為下一次迭代生成新的參數網格\n",
    "            if i < self.n_iterations - 1:\n",
    "                current_grid = self._generate_new_param_grid(iteration_best_params, i)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\n總耗時: {total_time:.2f} 秒\")\n",
    "        print(f\"最終最佳參數: {self.best_params_}\")\n",
    "        print(f\"最終最佳分數: {self.best_score_:.6f}\")\n",
    "        \n",
    "        # 輸出優化歷史摘要\n",
    "        print(f\"\\n優化歷史摘要:\")\n",
    "        for hist in self.optimization_history:\n",
    "            print(f\"迭代{hist['iteration']}: 樣本數={hist['sample_size']}, \"\n",
    "                  f\"參數數量={np.prod([len(v) for v in hist['param_grid'].values()])}, \"\n",
    "                  f\"分數={hist['best_score']:.6f}, 耗時={hist['iteration_time']:.2f}s\")\n",
    "        \n",
    "        return self, total_time\n",
    "\n",
    "# 初始參數範圍與一般 GridSearch 相同（保持不變）\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "optimized_knn_search = OptimizedRefinedAdaptiveKNN(knn_model, param_grid_knn, n_iterations=3)\n",
    "optimized_knn_search, total_duration = optimized_knn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 測試集評估\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    infer_time = time.time() - start\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n{model_name} 測試準確率: {acc:.6f}\")\n",
    "    print(f\"推理耗時: {infer_time:.2f} 秒\")\n",
    "    print(f\"分類報告:\\n{classification_report(y_test, y_pred)}\")\n",
    "    print(f\"混淆矩陣:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "    return acc\n",
    "\n",
    "final_accuracy = evaluate_model(optimized_knn_search.best_estimator_, X_test_scaled, y_test, \"KNN (自適應)\")\n",
    "print(f\"\\n總搜尋耗時: {total_duration:.2f} 秒\")\n",
    "# print(f\"與一般網格搜索({5130.49:.2f}秒)相比，速度提升: {5130.49/total_duration:.1f}倍\")\n",
    "# print(f\"準確率比較 - 目標: 0.998395, 實際: {final_accuracy:.6f}, 差異: {abs(final_accuracy-0.998395)*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徵標準化...\n",
      "(75383, 82)        Label\n",
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "...      ...\n",
      "75378      1\n",
      "75379      1\n",
      "75380      1\n",
      "75381      1\n",
      "75382      1\n",
      "\n",
      "[75383 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "print(\"特徵標準化...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print (X_test_scaled.shape, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin KNN model of adaptive grid searchCV...\n",
      "\n",
      "iteration 1/3\n",
      "best parameter: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "best grade: 0.999140\n",
      "execution time: 87.43 sec\n",
      "\n",
      "iteration 2/3\n",
      "best parameter: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "best grade: 0.999140\n",
      "execution time: 86.12 sec\n",
      "\n",
      "iteration 3/3\n",
      "best parameter: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "best grade: 0.999797\n",
      "execution time: 2040.25 sec\n",
      "\n",
      "total execution time: 2214.20 sec\n",
      "final best parameter: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "final best grade: 0.999797\n",
      "\n",
      " the history of optimized parameter:\n",
      "iteration1: best parameter={'n_neighbors': 3, 'p': 1, 'weights': 'distance'}, grade=0.999140, execution time=87.43s\n",
      "iteration2: best parameter={'n_neighbors': 3, 'p': 1, 'weights': 'distance'}, grade=0.999140, execution time=86.12s\n",
      "iteration3: best parameter={'n_neighbors': 3, 'p': 1, 'weights': 'distance'}, grade=0.999797, execution time=2040.25s\n",
      "\n",
      "KNN (adaptive) testing accuracy: 0.998395\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49763\n",
      "           1       1.00      1.00      1.00     25620\n",
      "\n",
      "    accuracy                           1.00     75383\n",
      "   macro avg       1.00      1.00      1.00     75383\n",
      "weighted avg       1.00      1.00      1.00     75383\n",
      "\n",
      "confusion_matrix:\n",
      "[[49644   119]\n",
      " [    2 25618]]\n",
      "\n",
      "total execution time: 2214.20 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 載入資料\n",
    "X_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_train_upsampled.csv')\n",
    "Y_train = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/Y_train_upsampled.csv')\n",
    "X_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/X_test_ext.csv')\n",
    "y_test = pd.read_csv('/Users/User/.vscode/thesis_experiment/CIC-DDoS-2019/01-12/y_test_ext.csv')\n",
    "y_train = Y_train.iloc[:, 0] if isinstance(Y_train, pd.DataFrame) else Y_train\n",
    "\n",
    "# 特徵標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class OptimizedRefinedAdaptiveKNN:\n",
    "    def __init__(self, estimator, param_grid, n_iterations=3):\n",
    "        self.estimator = estimator\n",
    "        self.initial_param_grid = param_grid\n",
    "        self.n_iterations = n_iterations\n",
    "        self.best_params_ = None\n",
    "        self.best_estimator_ = None\n",
    "        self.best_score_ = 0\n",
    "        self.optimization_history = []\n",
    "        self.allowed_k = sorted(param_grid['n_neighbors'])\n",
    "        self.sample_size = min(50000, len(X_train_scaled))  # 限制樣本大小以加速搜索\n",
    "        \n",
    "    def _get_refined_k_range(self, best_k, iteration):\n",
    "        \"\"\"動態調整k的搜索範圍，隨迭代變得更精細\"\"\"\n",
    "        if iteration == 0:\n",
    "            return self.allowed_k\n",
    "        elif iteration == 1:\n",
    "            min_k = max(min(self.allowed_k), best_k - 2)\n",
    "            max_k = min(max(self.allowed_k), best_k + 2)\n",
    "            refined_range = [k for k in self.allowed_k if min_k <= k <= max_k]\n",
    "            return refined_range if refined_range else [best_k]\n",
    "        else:\n",
    "            min_k = max(min(self.allowed_k), best_k - 1)\n",
    "            max_k = min(max(self.allowed_k), best_k + 1)\n",
    "            refined_range = [k for k in self.allowed_k if min_k <= k <= max_k]\n",
    "            return refined_range if refined_range else [best_k]\n",
    "\n",
    "    def _generate_new_param_grid(self, best_params, iteration):\n",
    "        \"\"\"根據迭代次數生成不同精細度的參數網格\"\"\"\n",
    "        new_grid = {}\n",
    "        if 'n_neighbors' in best_params:\n",
    "            best_k = best_params['n_neighbors']\n",
    "            new_grid['n_neighbors'] = self._get_refined_k_range(best_k, iteration)\n",
    "        if iteration == 0:\n",
    "            for param in ['weights', 'p']:\n",
    "                if param in self.initial_param_grid:\n",
    "                    new_grid[param] = self.initial_param_grid[param]\n",
    "        elif iteration == 1:\n",
    "            if 'weights' in best_params:\n",
    "                best_weight = best_params['weights']\n",
    "                other_weights = [w for w in self.initial_param_grid['weights'] if w != best_weight]\n",
    "                new_grid['weights'] = [best_weight] + other_weights[:1]\n",
    "            if 'p' in best_params:\n",
    "                best_p = best_params['p']\n",
    "                other_p = [p for p in self.initial_param_grid['p'] if p != best_p]\n",
    "                new_grid['p'] = [best_p] + other_p[:1]\n",
    "        else:\n",
    "            for param in ['weights', 'p']:\n",
    "                if param in best_params:\n",
    "                    new_grid[param] = [best_params[param]]\n",
    "        return new_grid\n",
    "\n",
    "    def _get_sample_indices(self, y, sample_size):\n",
    "        \"\"\"分層抽樣獲取訓練子集，確保類別平衡\"\"\"\n",
    "        if len(y) <= sample_size:\n",
    "            return np.arange(len(y))\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        indices = np.arange(len(y))\n",
    "        sample_indices, _ = train_test_split(\n",
    "            indices, \n",
    "            train_size=sample_size, \n",
    "            stratify=y, \n",
    "            random_state=42\n",
    "        )\n",
    "        return sample_indices\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()\n",
    "        current_grid = self.initial_param_grid\n",
    "        print(\"Begin KNN model of adaptive grid searchCV...\")\n",
    "        \n",
    "        sample_indices = self._get_sample_indices(y, self.sample_size)\n",
    "        \n",
    "        for i in range(self.n_iterations):\n",
    "            print(f\"\\niteration {i+1}/{self.n_iterations}\")\n",
    "            if i < self.n_iterations - 1:\n",
    "                X_iter = X[sample_indices]\n",
    "                y_iter = y.iloc[sample_indices] if hasattr(y, 'iloc') else y[sample_indices]\n",
    "                cv_folds = 3\n",
    "            else:\n",
    "                X_iter = X\n",
    "                y_iter = y\n",
    "                cv_folds = 5\n",
    "            \n",
    "            skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "            \n",
    "            gs = GridSearchCV(\n",
    "                self.estimator, \n",
    "                current_grid, \n",
    "                cv=skf,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                error_score='raise',\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            iter_start = time.time()\n",
    "            gs.fit(X_iter, y_iter)\n",
    "            iter_time = time.time() - iter_start\n",
    "            \n",
    "            iteration_best_params = gs.best_params_\n",
    "            iteration_best_score = gs.best_score_\n",
    "            \n",
    "            if i == 0 or iteration_best_score > self.best_score_ or i == self.n_iterations - 1:\n",
    "                self.best_params_ = iteration_best_params\n",
    "                self.best_score_ = iteration_best_score\n",
    "                self.best_estimator_ = self.estimator.set_params(**self.best_params_)\n",
    "                if i < self.n_iterations - 1:\n",
    "                    self.best_estimator_.fit(X, y)\n",
    "                else:\n",
    "                    self.best_estimator_ = gs.best_estimator_\n",
    "            \n",
    "            print(f\"best parameter: {iteration_best_params}\")\n",
    "            print(f\"best grade: {iteration_best_score:.6f}\")\n",
    "            print(f\"execution time: {iter_time:.2f} sec\")\n",
    "            \n",
    "            self.optimization_history.append({\n",
    "                'iteration': i+1,\n",
    "                'param_grid': current_grid,\n",
    "                'best_params': iteration_best_params,\n",
    "                'best_score': iteration_best_score,\n",
    "                'iteration_time': iter_time\n",
    "            })\n",
    "            \n",
    "            if i < self.n_iterations - 1:\n",
    "                current_grid = self._generate_new_param_grid(iteration_best_params, i)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\ntotal execution time: {total_time:.2f} sec\")\n",
    "        print(f\"final best parameter: {self.best_params_}\")\n",
    "        print(f\"final best grade: {self.best_score_:.6f}\")\n",
    "        \n",
    "        print(f\"\\n the history of optimized parameter:\")\n",
    "        for hist in self.optimization_history:\n",
    "            print(f\"iteration{hist['iteration']}: best parameter={hist['best_params']}, \"\n",
    "                  f\"grade={hist['best_score']:.6f}, execution time={hist['iteration_time']:.2f}s\")\n",
    "        \n",
    "        return self, total_time\n",
    "\n",
    "# 初始參數範圍\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "optimized_knn_search = OptimizedRefinedAdaptiveKNN(knn_model, param_grid_knn, n_iterations=3)\n",
    "optimized_knn_search, total_duration = optimized_knn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 測試集評估\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    infer_time = time.time() - start\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n{model_name} testing accuracy: {acc:.6f}\")\n",
    "    print(f\"classification_report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    print(f\"confusion_matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "    return acc\n",
    "\n",
    "final_accuracy = evaluate_model(optimized_knn_search.best_estimator_, X_test_scaled, y_test, \"KNN (adaptive)\")\n",
    "print(f\"\\ntotal execution time: {total_duration:.2f} sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
